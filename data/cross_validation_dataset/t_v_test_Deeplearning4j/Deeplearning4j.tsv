OQ	how to frame a network which reads paragraph and answer question from that? __eou__	user	0	1	1	2
FQ	d4jnewbie: Have you set up the examples and read trhough the code? Start there. __eou__	agent	0	1	0	0
IG	 [<-LINK->]  __eou__	agent	0	1	0	0
NF	i have done all these but this example doesn't statisfy my usecase. __eou__	user	0	1	0	0
FD	got held up how to proceed __eou__	user	0	1	0	0
IG	d4jnewbie: question answering systems are alotmore complicated than most of our examples... you're going to have to research the deep learning literature and build it yourself __eou__	agent	1	1	0	1
CQ	can you suggest  some steps to achieve question answering system from paragraph? __eou__	user	0	1	0	0
CQ	agibsonccc: can you suggest some steps to achieve question answering system from paragraph? __eou__	user	0	1	0	0
IG	d4jnewbie: I’d suggest to go to arxiv.org as first step __eou__	agent	1	1	0	1
NF	your question doesn’t have simple answer __eou__	agent	0	1	0	0

OQ	could you point to an example /doc how to provide dataset with multiple labels  (e.g. RecordReaderDataSetIterator ). The dataset has several labels, each can be yes or no (1 /0) , multiple "yes" could be set. __eou__	user	0	0	0	0
JK	vedina: Welcome! Here's a link to Deeplearning4j's Gitter Guidelines, our documentation and other DeepLearning resources online. Please explore these and enjoy! [<-LINK->]  __eou__	agent	0	0	0	0
JK	richgiomundo: Welcome! Here's a link to Deeplearning4j's Gitter Guidelines, our documentation and other DeepLearning resources online. Please explore these and enjoy! [<-LINK->]  __eou__	agent	0	0	0	0
PA	vedina: the iterator does that out of the box __eou__	agent	0	0	0	0
FD	You just specify the number of labels and you're set __eou__	agent	0	0	0	0
JK	hsali: Welcome! Here's a link to Deeplearning4j's Gitter Guidelines, our documentation and other DeepLearning resources online. Please explore these and enjoy! [<-LINK->]  __eou__	agent	0	0	0	0

OQ	Is it possible to build a (standard) fully recurrent neural network with backpropagation through time in DL4J? __eou__	user	0	1	1	2
IG	yes __eou__	agent	1	1	0	1
FD	Because the documentation justs says something about lstm __eou__	user	0	1	0	0
CC	oh, you mean non-lstm __eou__	agent	0	1	0	0
NF	hmm, not sure about that actually __eou__	agent	0	1	0	0
IG	relue: we only do lstms __eou__	agent	1	1	0	1
FD	and their bidirectional cousin __eou__	agent	1	1	0	1
UF	Ok thanks :) __eou__	user	0	1	0	0
IG	relue: 'vanilla' RNNs wouldn't be hard to implement, but we haven't needed them yet so haven't built them __eou__	agent	1	1	0	1
AC	It shouldnt be too hard to implement that. It just needs the unfolding of rnn into an mlp and then do slightly modified BP __eou__	user	0	1	0	0
AE	But maybe deep rnn aren't suitable for practical use, just researching deep rnn for time series prediction __eou__	user	0	1	0	0
AE	relue: LSTM is very useful for time series prediction too __eou__	agent	0	1	0	0

OQ	actually while we're on the topic, does remote UI reporting write to file or does the UI put the stats in memory? __eou__	user	0	1	1	2
IG	crockpotveggies: defaults to in memory though, but you can use either __eou__	agent	1	1	0	1
JK	one sec __eou__	agent	0	1	0	0
FQ	hmm, I wonder if that was the cause of my earlier problem __eou__	user	0	1	0	0
AE	crockpotveggies: I understand it that you can choose __eou__	agent	0	1	0	0
FD	either memory or file __eou__	agent	0	1	0	0
IG	 [<-LINK->]  __eou__	agent	0	1	0	0
FQ	<CODE> what does attach do? __eou__	user	0	1	0	0
IG	to the UI __eou__	agent	0	1	0	0
FD	you don't actually have to display the data when collecting it __eou__	agent	0	1	0	0
AE	nifty __eou__	user	0	1	0	0
FQ	I assume a single storage can handle multiple training instances? __eou__	user	0	1	0	0
PF	yep, that's the idea __eou__	agent	0	1	0	0
IG	currently all remote UI info will be posted to a single storage instance __eou__	agent	1	1	0	1
PF	good to know, that's going to save me a lot of headache :) __eou__	user	0	1	0	0

OQ	Hey guys, I have one last question around spark's word2vec implementation (newest version). Is there anyway to update existing weights, like the standalone word2vec version? For example, if I start with a corpus of 1 gb, then add 500 more mbs at a later time, can it do so without overwriting the existing vocab and inMemoryLookupTable? If not, is there a way to merge two lookup tables? (I know you can add vocab cache, but I don't see anything for the inMemoryLookupTable). __eou__	user	0	1	1	2
IG	dmmiller612: there are methods for that, but problem isn't really a merge of two tables, but merge of two huffman trees. __eou__	agent	1	1	0	1
FQ	ah, I didn't seen anything that did that in the word2vec implementation. Is it apart of the nlp package? __eou__	user	0	1	0	0
IG	dl4j-spark-nlp __eou__	agent	1	1	0	1
UF	thanks __eou__	user	0	1	0	0

OQ	I have a question about how nd4j find the location of native .so files.  All native .so files are packaged into a nd4j-native-0.7.0-linux-x86-64.jar file. But when javacpp loads .so libraries, normally it needs java.library.path to find the .so libraries. But I didn't find this setting.  so I wonder how javacpp find the location of native .so files. __eou__	user	0	1	1	2
IG	xuzhongxing: it's based on the classpath __eou__	agent	1	1	0	1
FD	javacpp has a loader class __eou__	agent	1	1	0	1
NF	But when I was trying a simple example of javacpp, it said UnsatisfiedLinkError. I have to set LD_LIBRARY_PATH to suppress it. I have the .so file on my classpath. __eou__	user	0	1	0	0
PA	AlexDBlack: I figured it out: __eou__	user	0	1	0	0
AC 	I need to include platform name in the directory in the jar file that contains the .so files. __eou__	user	1	1	0	1
UF	Thanks for pointing me to the source code of javacpp __eou__	user	0	1	0	0
JK	sorry, @ the wrong person.@agibsonccc __eou__	user	0	1	0	0

OP	I thought someone at DL4J would like to know:  The PredictGenderTrain  dl4j example frequently does not learn/converge (~50% error through all epochs).   It seems to work reliably when I reduce the   learningRate = 0.005;//GF was .01      So, you might update source code. __eou__	user	0	0	0	0
AE	gforman44: pull request would be even better :D __eou__	agent	0	0	0	0
FD	FYI: when it doesn\'t converge, it repeatedly gets:  "o.d.optimize.solvers.BaseOptimizer - Hit termination condition on iteration 0" errors. __eou__	user	0	0	0	0
NF	agibsonccc: Sorry, I'm not that sophisticated with GIT yet. __eou__	user	0	0	0	0
IG	 [<-LINK->]  __eou__	agent	0	0	0	0
AE	doesn't hurt to learn :D it's only a few commands __eou__	agent	0	0	0	0
IG	 [<-LINK->]  __eou__	agent	0	0	0	0
FD	It's widely documented __eou__	agent	0	0	0	0
AC	agibsonccc: OK, wow, I did it as a pull request.  That wasn't as hard as I thought.   You can quote me on that for future people. __eou__	user	0	0	0	0
PF	haha awesome __eou__	agent	0	0	0	0
PF	congrats! :D __eou__	agent	0	0	0	0
JK	Merged :D welcome to the world of open source __eou__	agent	0	0	0	0
PF	This is awesome. __eou__	user	0	0	0	0
UF	Thanks for giving me a push, Adam. __eou__	user	0	0	0	0
FD	I mean a pull. __eou__	user	0	0	0	0
JK	Or whatever. __eou__	user	0	0	0	0
JK	heh __eou__	agent	0	0	0	0

OQ	Is there an env variable that I can use to specify which BLAS to use (MKL vs openblas)? __eou__	user	0	1	1	2
IG	akhodakivskiy: If MKL is in your library path, it will get used, but you can disable that by setting the java.library.path system property to an empty string __eou__	agent	1	1	0	1
FQ	like this? -Djava.library.path="" __eou__	user	0	1	0	0
IG	Yes, that's one way __eou__	agent	0	1	0	0
NF	Hm, doesn't quite work. __eou__	user	0	1	0	0
FD	works like this though -$ LD_LIBRARY_PATH="" java Main __eou__	user	0	1	0	0
FD	There was this bug with OpenBLAS:C  [libopenblas.so.0+0x29bbcf]  sgemm_otcopy+0xef- have you guys had a chance to fix it in master? __eou__	user	0	1	0	0
AC	I'm trying to compare MKL vs OpenBLAS performance in my case __eou__	user	0	1	0	0
AE	Sure, it's only a build issue with OpenBLAS __eou__	agent	0	1	0	0
IG	 [<-LINK->]  __eou__	agent	0	1	0	0
FQ	So when I build from source - does the build also discover MKL automatically and link against it unconditionally? __eou__	user	0	1	0	0
FQ	Does this happen when building libnd4j or nd4j? __eou__	user	0	1	0	0
IG	lib __eou__	agent	0	1	0	0
AE	In my use case OpenBLAS is 3-4 times faster than MKL __eou__	user	0	1	0	0
UF	surprising. __eou__	agent	0	1	0	0
UF	Yeah.. __eou__	user	0	1	0	0

IG	On another note I'm also playing with updating existing input INDArray instance instead of allocating it every time, and the version with in-place update is also 2-3 times faster, i.e. [<-CODE->] vs [<-CODE->] __eou__	user	0	1	1	2
OQ	Would it be possible to have Nd4j reuse the same instances of INDArray instead of allocating them every time - while running activation? __eou__	user	0	1	0	0
IG	that happens on cuda. __eou__	agent	1	1	0	1
FD	by default __eou__	agent	1	1	0	1
FD	not on cpu though __eou__	agent	1	1	0	1
IG	Yeah, I'm talking about CPU __eou__	user	0	1	0	0
FD	That is while running the model in production __eou__	user	0	1	0	0

OQ	perceptoid: are you going to open an issue for the dropout problem when using keras model? it would be great! __eou__	user	0	1	1	2
IG	benqua: I'm doing some tests to learn more. If the problem is obvious feel free to open the issue - I can't describe it just yet. __eou__	agent	1	1	0	1
AE	perceptoid: the problem is not obvious for me (I don't know enough of the internal working of dl4j) but it seems it was for@raver119and@agibsonccc. Dropout has different meaning in keras and dl4j __eou__	user	0	1	0	0
PF	benqua: right ok :D __eou__	agent	0	1	0	0
AE	that's a simple fix __eou__	agent	0	1	0	0
FD	That's why I was telling him to just do something without dropout for now while@turambarfixes this __eou__	agent	0	1	0	0
FQ	ok. so no need to open an issue to track it down? __eou__	user	0	1	0	0

OQ	Good Morning (again!) Trying to run arbiter and trying to figure out how to create the DataProvider<DataSetIterator> from RecordReaderDataSetIterator. Trying  DataSetIterator dataTrain = new MultipleEpochsIterator(nTrainEpochs, new RecordReaderDataSetIterator(rr, 64)); but this is not splitting the dataset correctly. How to I create a  DataProvider from a RecordReaderDataSetIterator? __eou__	user	0	1	1	2
IG	jvence: you'd want to split the data yourself __eou__	agent	1	1	0	1
FD	jvence:  [<-LINK->]  __eou__	agent	1	1	0	1
FD	if you pre save the datasets you can use this __eou__	agent	1	1	0	1
FD	There's also balance minibatches: [<-LINK->]  __eou__	agent	1	1	0	1
FQ	agibsonccc: Can I use SplitTestAndTrain? __eou__	user	0	1	0	0
NF	not really __eou__	agent	0	1	0	0
FD	unless you have the whole dataset in memory __eou__	agent	0	1	0	0
IG	you could go through the iterator and randomly do split test train and save the results __eou__	agent	0	1	0	0
FQ	agibsonccc: when training my model, I use  SplitTestAndTrain on a RecordReaderDataSetIterator (after applying NormalizerMinMaxScaler) to load the data. Does this not work? __eou__	user	0	1	0	0
JK	well so again __eou__	agent	0	1	0	0
AE	you till have the problem of not having the whole dataset in memory __eou__	agent	0	1	0	0
IG	you could do split test and train on the batches and concatneate __eou__	agent	1	1	0	1
AE	my batch size is the entire data set so I should be fine __eou__	user	0	1	0	0
IG	then yeah split test and train will work __eou__	agent	1	1	0	1

AE	last time i’ve checked dl4j vs caffe, it was 0.6.0 -> 0.7.0 transition, and time was pretty close. __eou__	user	0	0	0	0
AE	A lot can change in even 6 months __eou__	agent	0	0	0	0
IG	We are pretty on par now __eou__	agent	0	0	0	0
AC	I would run your own benchmark __eou__	agent	0	0	0	0
IG	A 1 off paper will usually be biased towards research for 1 __eou__	agent	0	0	0	0
IG	for 2 tensorflow isn't the fastest __eou__	agent	0	0	0	0
FD	but you see people using it anyways __eou__	agent	0	0	0	0
AE	for some things caffe was faster, for other dl4j was faster __eou__	user	0	0	0	0
AC	I would just give it a shot first __eou__	agent	0	0	0	0
IG	actually, any framework uses the same tools. __eou__	user	0	0	0	0
IG	we have a standard lenetmnist benchmark [<-LINK->]  __eou__	agent	0	0	0	0
IG	openmp for cpu __eou__	user	0	0	0	0
PF	right __eou__	agent	0	0	0	0
IG	we have cudnn too __eou__	agent	0	0	0	0
IG	openblas/blas for blas __eou__	user	0	0	0	0
FQ	based on the "last visited" dates it was finished around april? which means 0.4-rc3.8 (6 releases ago, and before our major c++ backend rewrite) __eou__	agent	0	0	0	0
IG	cuda/cudnn for gpus __eou__	user	0	0	0	0
PF	right __eou__	agent	0	0	0	0
FD	yeah that was when we had java __eou__	agent	0	0	0	0
FD	not c++ __eou__	agent	0	0	0	0
IG	so you can’t really expect huge time differences now __eou__	user	0	0	0	0
IG	it’s +- the same time frames, so only ecosystem should matter __eou__	user	0	0	0	0

JK	my original idea in 2003 was to build a robot that uses swarm technique to collaborative robots __eou__	user	0	0	0	0
JK	then have like a dozen of them working together to do fun stuff __eou__	user	0	0	0	0
JK	it's the reason I got a 3D printer __eou__	user	0	0	0	0
FD	It'd be really awesome if you can get a dozen of them running rl4j __eou__	agent	0	0	0	0
JK	and just driving around. __eou__	agent	0	0	0	0
JK	Automatically avoiding eachother. __eou__	agent	0	0	0	0
FD	one of the goals was to use CV to build racing robots that could drive around a track as fast as Mindstorm motors can go __eou__	user	0	0	0	0
FD	then people could have robot races __eou__	user	0	0	0	0
FD	they could train the robots, post their models to github and share __eou__	user	0	0	0	0
JK	instead of jumping right to that, I'm doing robot tag first __eou__	user	0	0	0	0
JK	it's more like a robot time trial though, Pi doesn't have enough juice for robots to race each other __eou__	user	0	0	0	0
FD	Yeah.  Maybe if you had a bunch of robots connected to tegra x1s __eou__	agent	0	0	0	0
FD	"Data Loaded.  Vocabulary Size: 63674 Total lines: 40331236" Wow, that\'s not going to fit in RAM... __eou__	agent	0	0	0	0
JK	haha... you refering to Nvidia's tegra... aren't those suckers still expensive __eou__	user	0	0	0	0
FD	About $500ish was it? __eou__	agent	0	0	0	0
FD	I'm thinking price range of under $30 __eou__	user	0	0	0	0
JK	so that middle/high school kids and build them __eou__	user	0	0	0	0
JK	having them go to their parents and say "Mom, can I have 600 to build a cool robot that races around a track?" __eou__	user	0	0	0	0
JK	might get the response "sure, go get a job!" __eou__	user	0	0	0	0
PF	True.  but plenty of kids play with gasoline RC cars and model airplanes that are in that range. __eou__	agent	0	0	0	0
PF	true, I had rich friends that did that for a hobby in the 80's, but when they crashed them to pieces, their parents were pissed __eou__	user	0	0	0	0
JK	only the ones with jobs could keep racing, the rest stopped once their cars were toast __eou__	user	0	0	0	0
JK	There are few hobbies as expensive as racing. __eou__	agent	0	0	0	0
JK	like snow boarding :) that's a couple hundred each time __eou__	user	0	0	0	0

OQ	How can I make read data format .h5 (HDF5) into DataSetIterator? The data structure of my .h5 file is like this "/GroupA/Group*/(-DataSet1 -DataSet2 -DataSet3)". I can read it easily and assign it to NDArray but I dont how to assign it to DataSetIterator. __eou__	user	0	1	1	2
IG	PhavMakara_twitter: you can use the new javacpp based presets __eou__	agent	1	1	0	1
FD	 [<-LINK->]  __eou__	agent	1	1	0	1
FD	you would use that with dataset.load __eou__	agent	1	1	0	1
FD	if you can do a chain of saves in to a file this should work :D __eou__	agent	1	1	0	1
FD	What I would maybe consider doing if you can would be prepending an int and reading that in to represent the count of the number of datasets __eou__	agent	1	1	0	1
FD	then you can just chain save and load calls __eou__	agent	1	1	0	1
AC	Okay let me clarify your answer. You suggest me to chuck my own data without using DataSetIterator right? I never use that javacpp before. It probably takes me some time to really get what you suggest. __eou__	user	0	1	0	0
CC	PhavMakara_twitter: it's just java bindings for the c++ hdf5 __eou__	agent	0	1	0	0
FD	same api __eou__	agent	0	1	0	0
FD	your goal is to basically get an input stream __eou__	agent	0	1	0	0
FD	and an outputstream __eou__	agent	0	1	0	0
FD	that you can write and read raw bytes from __eou__	agent	0	1	0	0
FD	I just told you the binary format to use from there :D __eou__	agent	0	1	0	0

OQ	Within class LenetMnistExample in deeplearning4j example package, when you train the model, how can you specify the input data label to fit the model? I only see you using model.fit(inputData) without specific the label with it. __eou__	user	0	0	0	0
PA	DataSet contains input and label fields __eou__	agent	0	0	0	0
FQ	But if have separate dataset how can I combine them __eou__	user	0	0	0	0
FD	for example by dataset input is 3 dimension and output is 1 dimensional output __eou__	user	0	0	0	0
FD	Based on this link [<-LINK->] , Can I just declare it like this Dataset input = new Dataset(input,Label) while both input and label are NDArray with different dimension __eou__	user	0	0	0	0
PA	input and label fields can be any INDArrays (that are appropriate for the network you are training, anyway) __eou__	agent	0	0	0	0
FD	and yes, you create it using that constructor __eou__	agent	0	0	0	0
PF	Thank __eou__	user	0	0	0	0

OQ	AlexDBlack: alex could you please explain the meaning of iteration number in the BasicRNNExample? __eou__	user	0	1	1	2
IG	suppose you have 3 examples: A,B,C in a DataSetIterator.iterations(1): fit(DataSetIterator) does training like ABC.iterations(3): fit(DataSetIterator) does training like AAABBBCCC __eou__	agent	1	1	0	1
FD	usually .iterations(1) is what you want __eou__	agent	1	1	0	1
FD	that was an example contributed by the community fwiw __eou__	agent	1	1	0	1
PF	thank you. __eou__	user	0	1	0	0
AE	So in that example, it is similar to the epoch parameter __eou__	user	0	1	0	0
CC	if all data is in one DataSet object: then .iterations(x) and fitting for x epochs are identical __eou__	agent	0	1	0	0
FD	in general, similar to epochs, but different order __eou__	agent	0	1	0	0
FD	repeated order like that isn't usually a good idea __eou__	agent	0	1	0	0
PF	I see. __eou__	user	0	1	0	0
FQ	In what situation setting iterations > 1 makes sense? __eou__	user	0	1	0	0
IG	not many, to be honest. full batch/dataset learning (usually only possible on very small data sets), andmaybeif data loading is very costly __eou__	agent	0	1	0	0
PF	I see __eou__	user	0	1	0	0

OQ	Hey, sorry for interrupting you, but I got a quick question, wondering if someone can answer it... If I run the following line of code on a pretty large Nd4j array (no dl4j involved) with tons of negative infinity values in it, a lot of messages saying "Number: -Infinity" get logged. Is this intentional, and if so, why?BooleanIndexing.applyWhere(array, new Or(Conditions.isInfinite(), Conditions.isNan()), 10);Does not happen with this piece of code:BooleanIndexing.applyWhere(array, new Or(Conditions.isInfinite(), Conditions.isNan()), new StableNumber(StableNumber.Type.DOUBLE));Nd4j 0.7.1 __eou__	user	0	0	0	0
IG	StillNoNumber: probably just a bug, leaked debug messsage __eou__	agent	0	0	0	0
AC	StillNoNumber: i’ll check that right now __eou__	agent	0	0	0	0
JK	yes, because i’ve wrote that one __eou__	agent	0	0	0	0
PF	:) __eou__	agent	0	0	0	0
FQ	raver119: Assumed so. Thanks anyway, should I file a report or something? __eou__	user	0	0	0	0
GGAC	StillNoNumber: thanks, no need, i’m already opening nd4j __eou__	agent	0	0	0	0
UF	Alright :D __eou__	user	0	0	0	0
CC	i mean - you’ve already reported it :) __eou__	agent	0	0	0	0
IG	yeah but you might prefer it if I report it somewhere so you can organize your to-do-list or whatever __eou__	user	0	0	0	0
IG	raver119: Found it, line 238 in BooleanIndexing __eou__	user	0	0	0	0
JK	in case you haven't yet __eou__	user	0	0	0	0
JK	:P __eou__	user	0	0	0	0
NF	StillNoNumber: it’ll also disable that spam :( __eou__	agent	0	0	0	0

OQ	the autoencoder example is quite simple... so I have still plenty of questions. first of all, there are many types of autoencoders such as Denoising autoencoder, Sparse autoencoder, Variational autoencoder, Contractive autoencoder... which does DL4J support?do I need to do something special to make an autoencoder that is  Denoising autoencoder, Sparse autoencoder, Variational autoencoder or Contractive autoencoder? __eou__	user	0	1	1	2
IG	variational autoencoder now available at current master __eou__	agent	1	1	0	1
FD	alex merged it few days ago __eou__	agent	1	1	0	1
PF	nice! __eou__	user	0	1	0	0
IG	daredemo: There are small special things for each of the subtypes of autoencoders.  Sparse has a penalty (usually L1) which encourages sparse activation in the inner-most hidden layer.  Denoising adds noise on the input and attempts to reconstruct a noise free output.  Variational autoencoders instead learn a mean and standard deviation instead of an explicit internal state, then randomly generate a hidden state from those values and reconstruct. __eou__	agent	0	1	0	0
FD	Of the bunch, denoising is perhaps the easiest to train, since you just had to do train(myExamples + noise, myExamples) __eou__	agent	0	1	0	0
FQ	JosephCatrambone: I know the differences in the autoencoders. just wondering how to implement them in DL4J (for example the L1 stuff that you mentioned) __eou__	user	0	1	0	0
CC	Ah.  Sry.  I misunderstood. __eou__	agent	0	1	0	0
NF	In this respect, I can't really help.  I'm here for the ND4j stuff.  ;) __eou__	agent	0	1	0	0
CQ	I mean, I know, but I don't know the exact math behind them __eou__	user	0	1	0	0
GG	'tiz OK :D __eou__	user	0	1	0	0

OQ	agibsonccc: actually, can I use a different backend, that's software based and not using native stuff? __eou__	user	0	1	1	2
IG	we don't have a pure java backend, no. it'd be too slow __eou__	agent	1	1	0	1
CC	no...I mean this just shouldn't be a problem __eou__	agent	0	1	0	0
JK	and...that __eou__	agent	0	1	0	0
CC	I mean javacpp hasn't been that big of a problem __eou__	agent	0	1	0	0
NF	I really don't understand what's going on __eou__	user	0	1	0	0
AC	I looked inside javacpp __eou__	user	0	1	0	0
AE	it seems to be using java.io.tmpdir __eou__	user	0	1	0	0
CQ	have you hit the debugger with Loader? __eou__	agent	0	1	0	0
FD	 [<-LINK->]  __eou__	agent	0	1	0	0
NF	but I don't get how it's going to /private when tmpdir point to /var __eou__	user	0	1	0	0
IG	 [<-LINK->]  __eou__	agent	1	1	0	1
AC	File an issue on javacpp with as much information as you can get __eou__	agent	1	1	0	1
AE	this just sounds like sam needing to update the docs __eou__	agent	1	1	0	1
IG	 [<-CODE->] this is the whole output btw __eou__	user	0	1	0	0
AE	it doesn't really say where the error actually occurs __eou__	user	0	1	0	0
AC	file an issue on nd4j there then __eou__	agent	0	1	0	0
AC	give as much detail as you can __eou__	agent	0	1	0	0
UF	alright __eou__	user	0	1	0	0
GG	thanks for the help __eou__	user	0	1	0	0
AC	bogdanteleaga: please add your pom.xml there __eou__	agent	0	1	0	0
FQ	I guess what I'm confused about here is what does it actually try to load? Should the computer already have a libnd4j? __eou__	user	0	1	0	0
FQ	Or does it gather some native ops and puts them in a .dylib and then tries to load from it? __eou__	user	0	1	0	0
IG	It usually loads it from an extracted internal jar __eou__	agent	0	1	0	0
FD	like I said just file an issue __eou__	agent	0	1	0	0
AC	saudet: will get back to you __eou__	agent	0	1	0	0
FD	he wrote the code __eou__	agent	0	1	0	0
AE	javacpp isn't third party __eou__	agent	0	1	0	0
FD	we control and support this too __eou__	agent	0	1	0	0

OQ	Word2Vec: I have 2 words as vector representations. After I averaged them, I have one vector representation. How do I lookup the table with the vector representation? __eou__	user	0	1	1	2
IG	the same way __eou__	agent	1	1	0	1
FD	wordsNearest __eou__	agent	1	1	0	1
FD	it accepts vectors as well as words __eou__	agent	1	1	0	1
FQ	raver119: where can I find a decent documentation containing all the functions relevant to Word2Vec?Thanks! __eou__	user	0	1	0	0
IG	in javadoc __eou__	agent	0	1	0	0
FD	 [<-LINK->] __eou__	agent	0	1	0	0

OQ	downloaded the most recent deeplearning4j/examples. The following occurs when I run the examples if they are related to mnist. Not sure if this is a known issue or not.o.d.b.MnistFetcher - Downloading mnist...<CODE> __eou__	user	0	1	1	2
IG	thewzhang: that's just a network connection problem __eou__	agent	1	1	0	1
FD	try again, and if necessary, delete the MNIST directory in your home directory __eou__	agent	1	1	0	1
PFAC	AlexDBlack: , thank you! I removed the MNIST directory and now it is working. Do not feel that it is a network connection problem. __eou__	user	0	1	0	0
IG	it was most likely caused by a network connection issue while downloading __eou__	agent	0	1	0	0
PF	thanks, Alex. MNISTAnomalyExample worked and MLPMnistTwoLayerExample is working. __eou__	user	0	1	0	0
GG	great __eou__	agent	0	1	0	0
IG	also: anomaly detection using a variational autoencoder should perform better... variational autoencoders will be available next release [<-ISSUE->]  __eou__	agent	0	1	0	0

OQ	Hi@AlexDBlack, one question regarding  the MNISTAnomalyExample: when outputting the Worst(High Rec. Err) digits (or called outliers), are they correctly recognized ? In other words, they are recognized as ground-truth digits, but have large reconstruction error. __eou__	user	0	1	1	2
IG	anomaly detection and classification are different tasksthere is no "correctly recognized" in anomaly detection __eou__	agent	1	1	0	1
FQ	the output Worst(High Rec. Err) digits are considered as anomalies/outliers? __eou__	user	0	1	0	0
CC	yes __eou__	agent	0	1	0	0
AE	if this is to demo a simple autocoder, it is fine. But if it is to demo the accuracy of the model, it is inadequate -- many outliers do not look like outliers. __eou__	user	0	1	0	0
CC	thewzhang: the autocoder doesn\'t know what "outlier" means __eou__	agent	0	1	0	0
FD	it is an example of using the values from the autoencoder to proximate what WE would consider outliers __eou__	agent	0	1	0	0
PF	daredemo: , got it, thanks! __eou__	user	0	1	0	0

IG	I\'m reading about the rnn stuff and it says "It is not possible to change the number of examples between calls of rnnTimeStep" __eou__	user	0	1	1	2
OQ	I'm trying to understand this: to make a prediction, I need the previous state, but if I call rnnClearPreviousState(), this clears the previous... which now allows me to use any number of examples I want... but because previous state was cleared... this means that I'm back in the beginning? __eou__	user	0	1	0	0
FD	let's say I have daily data, and I do at first 2 examples (days) at a time... after some time I've reached say Thursday and could predict Friday, but if I do rnnClearPreviousState(), then I'm back to Monday? __eou__	user	0	1	0	0
IG	it's pretty uncommon that you want to predict the next steps of some number of time series,andstart predicting for a new time series at the same time __eou__	agent	1	1	0	1
FD	it gets hard to track, too __eou__	agent	1	1	0	1
FD	in principle: you can manually set the state __eou__	agent	1	1	0	1
FD	it's just arrays, and adding more examples means a larger dimension 0 for the state __eou__	agent	1	1	0	1
CQ	I mean is performance so critical that you really need to do that? __eou__	agent	0	1	0	0
CC	if not, I'd suggest keeping them separate __eou__	agent	0	1	0	0
FQ	AlexDBlack: I'm not yet even trying to optimize, I'm not sure what it is doing or supposed to be doing... for example, if I do single step, then I get next day, right? if I do say 2 examples/days, then I predict the day after tomorrow? or still just tomorrow? __eou__	user	0	1	0	0
CQIG	have you read this? [<-LINK->]  __eou__	agent	0	1	0	0
CQIG	and the javadoc? [<-LINK->]  __eou__	agent	0	1	0	0
CC	that's exactly what I'm reading (not yet the javadoc though) __eou__	user	0	1	0	0
FQ	so 3 examples would mean tomorrows prediction in 3 locations? __eou__	user	0	1	0	0
IG	right, if you feed in an array with size(0) == 3, then that's just a batched prediction for 3 separate examples __eou__	agent	0	1	0	0
FD	works exactly the same way as a training minibatch or standard forward pass in that respect __eou__	agent	0	1	0	0
PF	OK, got it now __eou__	user	0	1	0	0
GG	thanks@AlexDBlack __eou__	user	0	1	0	0
GG	sure, np __eou__	agent	0	1	0	0

OQ	still struggling to grasp the concepts to design a RNN networklet\'s say I wanted to detect motions/swipes on "touch pad" that consists of n x n sensors that record the state at a given interval. The users obviously do not make the motions identically, including the speeds might be different. So, now I have two questions:1) should I use a single n x n conv layer as input? or should I use some mega large input that contains all the n x n frames until the slowest motion is completed?2) if I used just single n x n as input, how should the training labeling be done? logically it seems that the label should be when the motion is completed, that is in the end, but should the other frames from the first to the last frame also be labeled the same? __eou__	user	0	1	1	2
IG	daredemo: You could use a CNN to obtain a single vector representation and then feed that into an RNN. Another approach I think of is to capture touchpad "activation" in a single matrix and let them decay with each timestep, so that most recent values will be 1 and old values will be close to zero and then apply a CNN to that single matrix. The problem with tihs approach is that you would need to detect start and end (maybe with another net?) __eou__	agent	1	1	0	1
FQ	Paranaix: "You could use a CNN to obtain a single vector representation", could you elaborate on this? do you mean by this that would build input layer that is m frames deep? [m x n x n] if my frame is [n x n ]? because this seems a bad idea, as it would require a lot of computing each step. some kind of hidden Markov model would be preferred, when I would only need to know the previous state, not m previous states __eou__	user	0	1	0	0
IG	daredemo: [n x n] -- CNN --> [m x 1] ---> RNN __eou__	agent	0	1	0	0
FQ	Paranaix: so that\'s my "1)" with single [n x n] input? __eou__	user	0	1	0	0
CC	Yes but with an RNN afterwards __eou__	agent	0	1	0	0
CQ	Or did you mean that? __eou__	agent	0	1	0	0
CC	of course, the beginning of my question implied that I'm doing RNN :D __eou__	user	0	1	0	0
FQ	but if I use the [ n x n ] input, I\'m then struggling with the "2)": how do I label my data?when the finger touches the middle of the touch pad, it could then move anywhere, up down left right; so it would seem strange to label it as "up" even if it is part of "up" motion... or should I? or should those intermediate steps be all classified as "meh?" :D or some intermediate classifier like "doing up" and only the end would be "up"? __eou__	user	0	1	0	0
FQ	in other words, in the sequence of "up", should I classify the first frame also as "up" for training? __eou__	user	0	1	0	0

OQ	so what is your advice for efficient gpu computing so that may be we may get one in the future? __eou__	user	0	1	1	2
IG	Get a titan if you can __eou__	agent	1	1	0	1
FD	That's the baseline __eou__	agent	1	1	0	1
FD	Either that or a high end gaming laptop with 1 of the new gtx cards __eou__	agent	1	1	0	1
IG	xx70 gpu __eou__	agent	0	1	0	0
FD	that's lowest end efficient for math __eou__	agent	0	1	0	0
FD	970 __eou__	agent	0	1	0	0
FD	1070 __eou__	agent	0	1	0	0
JK	etc __eou__	agent	0	1	0	0
FD	and everything above __eou__	agent	0	1	0	0
FD	xx60 gpus are cheaper, but significantly slower __eou__	agent	0	1	0	0
FD	below xx60 - not even worth using usually __eou__	agent	0	1	0	0
FD	i.e. 940/945 gpus etc __eou__	agent	0	1	0	0
FQ	what about this [<-LINK->]  __eou__	user	0	1	0	0
IG	titan is the best from consumer gpus __eou__	agent	0	1	0	0
FQ	is it also a good one? __eou__	user	0	1	0	0
IG	yep, that's fantastic titan gpu __eou__	agent	0	1	0	0
FD	yes, best of consumer-grade gpus at this moment __eou__	agent	0	1	0	0
FQ	ok if we buy this can we feel the improvements substantially in the gpu computing for machine learning? __eou__	user	0	1	0	0
FD	i guess you need to do some reading __eou__	agent	0	1	0	0
FD	gpus are not magic black boxes __eou__	agent	0	1	0	0
FD	on big tasks they shine __eou__	agent	0	1	0	0
FD	on small tasks they suck __eou__	agent	0	1	0	0
PF	i see __eou__	user	0	1	0	0
FD	i.e. on my pc with gtx 1070 gpu in single gpu mode, cuda is faster then cpu somewhere around x3-x4 __eou__	agent	0	1	0	0
FD	on that example you was running __eou__	agent	0	1	0	0
FD	with higher dimensions - difference gets higher __eou__	agent	0	1	0	0
FD	but it's also possible to get difference smaller __eou__	agent	0	1	0	0
PF	yes __eou__	user	0	1	0	0
PD	if you'll scroll up chat, you'll see some guy today had issues with small rnn model, which were not fast enough on gpu __eou__	agent	0	1	0	0
FD	like 5-7 hours ago __eou__	agent	0	1	0	0
AE	gpus are not magic boxes :) __eou__	agent	0	1	0	0
AE	they have own pro's and con's __eou__	agent	0	1	0	0
FD	so nobody will be able to say will you benefit or not, without detailed knowledge of the problems you're going to work with __eou__	agent	0	1	0	0

OQ	daredemo: "the webpage talk about input and output masks but only show one layer... is the input mask for only the rnn output layer? or is that for the first/input layer even if you have other non-rnn layers before it?"output mask is used only with RnnOutputLayerinput mask really only applies if you have one or more dense layers before your RNN layers, as say tanh(0 x weights + bias) != 0 in general... for RNN layers only, it\'s equivalent to just setting the masked inputs to 0 anyway. So strictly speaking, you don\'t need input mask for RNN-only networks (but we have no way of knowing that at data loading time) __eou__	user	0	1	1	2
CQ	AlexDBlack: only dense layers? not in case of CNN? __eou__	agent	0	1	0	0
NF	daredemo: honestly? we probably should have it for CNNs as well... but I don't think it's in there currently __eou__	user	0	1	0	0
AC	AlexDBlack: I'm just asking questions :D I know nothing :D trying to figure the RNN part out, but probably won't have any meaningful training data before next week __eou__	agent	0	1	0	0
IG	daredemo:  [<-ISSUE->] fyi __eou__	user	1	1	0	1
FQ	araymer: can't access that (I've requested access though) __eou__	user	0	1	0	0
PFAC	thanks ok, so looking at that: I'd probably use a multi-dimensional RNN for that [<-LINK->]  __eou__	user	0	1	0	0

OQ	Guys help please. I don't understand what each gate in LSTM architecture produce. Is it a number or a vector? If I'm not wrong  sigmoid function ALWAYS produces only one number in range from 0 to 1. Or it is possible that every gate produces target vector that was obtained by applying sigmoid function to each element of  input vector? __eou__	user	0	1	1	2
IG	each gate produces a single number in range 0 to 1. you have 4 gates per LSTM unit, and multiple units per LSTM layer __eou__	agent	1	1	0	1
CQ	Is number of units == LSTM.nOut(numberUnits) of layer actually? __eou__	agent	0	1	0	0
FQ	so every LSTM block produces number and not a vector? __eou__	user	0	1	0	0
CC	fahman: yes __eou__	agent	0	1	0	0
CC	by LSTM block I mean LSTM unit __eou__	user	0	1	0	0
IG	borjka: yes, it's the same as any other RNN (or, any other network in general) - each unit gives a single output/number __eou__	agent	1	1	0	1
FD	it's all vectorized for implementation though, across all units __eou__	agent	1	1	0	1
PF	really thank you! everything became so clear __eou__	user	0	1	0	0

IG	hello, in MNIST for experts example I can see pretrain called on builder __eou__	user	0	1	1	2
OQ	what kind of pretraining will be used if it is set to true __eou__	user	0	1	0	0
IG	Pretraining is special option for autoencoders/rbms __eou__	agent	1	1	0	1
FQ	can I use it to pretrain conv net weights using RBM automatically? __eou__	user	0	1	0	0
CQ	I should be clearer: I want to do pretraining using RBM and then transfer the weights to conv net before starting backprop. will Builder.pretrain(true) do that for me? __eou__	user	0	1	0	0

OQ	My computer does not have a GPU. Is it possible for me to build the whole project locally? __eou__	user	0	1	1	2
IG	See 2nd comment: [<-ISSUE->]  __eou__	agent	1	1	0	1
FQ	That means "Building the CUDA Backend" is not necessary? __eou__	user	0	1	0	0
CC	as long as you skip it you don't have to __eou__	agent	0	1	0	0
CQ	Is there a reason you're building from source though? __eou__	agent	0	1	0	0
CQ	You know you don't need to right? __eou__	agent	0	1	0	0
CC	I want to change the loss function. __eou__	user	0	1	0	0
IG	You can add a custom one without compiling nd4j though __eou__	agent	0	1	0	0
FD	for some special reasons. __eou__	user	0	1	0	0
ID	 [<-ISSUE->]  __eou__	agent	0	1	0	0
FD	It doesn't matter what they are :D there's an example right there of how to do it without compiling dl4j __eou__	agent	0	1	0	0
IG	Our model is very special __eou__	user	0	1	0	0
IG	You can also do custom layers __eou__	agent	0	1	0	0
FQ	is there some instructions I can follow? __eou__	user	0	1	0	0
CQ	on what? custom layers? __eou__	agent	0	1	0	0
CC	yes __eou__	user	0	1	0	0
AC	Again - please listen to me when I say file an issue with what you're missing :D __eou__	agent	0	1	0	0
FD	We have examples __eou__	agent	0	1	0	0
FD	if you want step by step tutorials tell us what __eou__	agent	0	1	0	0
FD	We have a dedicated person who does that stuff __eou__	agent	0	1	0	0
FD	they read issues __eou__	agent	0	1	0	0
FD	 [<-LINK->]  __eou__	agent	0	1	0	0
CC	custom layers and custom  loss functions __eou__	user	0	1	0	0
IG	We have basics __eou__	agent	0	1	0	0
FD	the readme.me is right there for it __eou__	agent	0	1	0	0
FD	readme.md* __eou__	agent	0	1	0	0
FD	if you want more then tell us __eou__	agent	0	1	0	0
PF	okay __eou__	user	0	1	0	0

OQ	Has anyone used COSINE_PROXIMITY as a loss function for outputs and if yes, for what use case? __eou__	user	0	1	1	2
IG	fahman: re: cosine proximity - I've never used it (but yes, it's all tested/gradient checked)... was built partly for our keras import functionalitybut I believe this is one application: [<-LINK->]  [<-LINK->] (compare eq 3 vs the comments of the mathematical form in the code comments) __eou__	agent	0	1	0	0
NF	Yes I thought I could use it to loss compare word embeddings, but somehow I cant manage to set other hyperparameters. I get always NaN as score __eou__	user	0	1	0	0
FD	Gonna check the paper __eou__	user	0	1	0	0
IG	and re: masking arrays -@eralyhas explained it well... just to reiterate: the net always outputs something at each time step, even with maskingyou can use this to manually zero them if you want: [<-LINK->] during training we use the mask to set the errors (loss function gradients) to 0 - the network's predictions are thus ignored for those time steps __eou__	agent	1	1	0	1
PF	Ye@eraly's explanation was good, didn't realized the masking worked that way but its perfectly fine __eou__	user	0	1	0	0

OQ	im stuck after reading in the data..like how to pass the data to a CNN..any input into that. __eou__	user	0	0	0	0
CQ	well, do you have DataSet objects yet? __eou__	agent	0	0	0	0
FD	that's why I was saying use CSVRecordReader + RecordReaderDataSetIterator __eou__	agent	0	0	0	0
FD	then it's pretty straightforward __eou__	agent	0	0	0	0
AC	ok. i wil try that..can i get back if i have any problem ? __eou__	user	0	0	0	0
CC	sure. start with this: [<-LINK->] then adapt it based on my earlier comments (delimiter, regression, etc) __eou__	agent	0	0	0	0
PFAC	ok..thank you.. i was following that example to read in the data. I wil explore further and wil try. Thank you __eou__	user	0	0	0	0

OQ	Hi. Is there a place for deeplearning pre-trained model (not only model, but weights)? I am looking for a way to use pre-trained VGG16 in dl4j. Any pointer? __eou__	user	0	1	1	2
IG	benqua: We don't have weights yet. The plan is to add that to: [<-LINK->] when we do __eou__	agent	1	1	0	1

OQ	is there anything in datavec thta would help me create separate feature/label files, like the ones used in the UCI classification example, or will I have to create them "manually" for my own time series? __eou__	user	0	1	1	2
IG	dan-lind: you'd have to do that manually but if you have a vision for how such a feature would work feel free to file an !issue __eou__	agent	1	1	0	1
FD	something like that wouldn't be out of the scope of datavec __eou__	agent	1	1	0	1

OQ	anyone know what would be a common cause of multiLayerNetwork.output() returning NaN? __eou__	user	0	1	1	2
IG	TrentWDB: Welcome! Here's a link to Deeplearning4j's Gitter Guidelines, our documentation and other DeepLearning resources online. Please explore these and enjoy! [<-LINK->]  __eou__	agent	1	1	0	1
IG	if you head to the tuninghelp room I think there's some peeps who can get more intimate with your problem __eou__	agent	1	1	0	1
FD	!tuningroom __eou__	agent	1	1	0	1
CQ	Accuracy is low or network isn't learning? Start by reading [<-LINK->] and [<-LINK->]  __eou__	agent	0	1	0	0
PF	thanks guys __eou__	user	0	1	0	0

GG	hi, __eou__	user	0	1	1	2
GG	Good Evening. __eou__	agent	0	1	0	0
JK	mrseven7seven: @iw876guys, just go straight to your questions. no need to wait till someone replies to your abstract "hi!" __eou__	agent	0	1	0	0
JK	you'll get answers faster this way :) __eou__	agent	0	1	0	0
OQ	how to get an image (with rank 4) in a RBM? (channels = 1) my first idea is to flat dimensions 3 and 4 to form img_heigth*img_width columns, bad idea? __eou__	user	0	1	0	0
IG	rbm kinda expects vector as input __eou__	agent	1	1	0	1
FD	so just flatten your images __eou__	agent	1	1	0	1
FD	there's method available for that, Nd4j.toFlattened() __eou__	agent	1	1	0	1
GG	ok, thanks __eou__	user	0	1	0	0

OQ	is it somehow possible to reverse engineer the filename from an instance in a DataSetIterator? __eou__	user	0	1	1	2
FD	filename of video/image etc. __eou__	user	0	1	0	0
IG	someonedeep: yes, you have to enable meta data tracking and then you can get it from the DataSets __eou__	agent	1	1	0	1

OQ	HI How to run deeplearning4J on hadoop by using mapreduce? Is there any examples? __eou__	user	0	1	1	2
IG	there’s none, mr isn’t supported anymore __eou__	agent	1	1	0	1
FD	spark is the way to go __eou__	agent	1	1	0	1
IG	xuzonghan: we had it at 1 point but no one was willing to pay for it __eou__	agent	1	1	0	1
JK	it was supported earlier, but ^^^ __eou__	agent	0	1	0	0
FD	we have salaried engineers working on dl4j __eou__	agent	1	1	0	1
FD	if something is a maintenance burden we cut it __eou__	agent	1	1	0	1
FD	we did that with spark.ml too __eou__	agent	1	1	0	1
FD	same thing __eou__	agent	1	1	0	1
FD	maintaining 2 versions of spark wasn't good for us __eou__	agent	1	1	0	1
UFAC	OK, I will switch to spark too :) __eou__	user	0	1	0	0

OQ	did I just dream that there were AWS AMIs available for dl4j? Can't find any __eou__	user	0	1	1	2
FD	Perhaps it's just not in my region __eou__	user	0	1	0	0
IG	dan-lind: we don't have anything up to date up there - we do have the docker containers though: [<-LINK->]  __eou__	agent	1	1	0	1

OQ	Where is "getLayer()" method defined in the code base?  In the class MultiLayerNetwork, the method "init()" calls a method "conf.getLayer()" but I can\'t find where that method is define.  IntelliJ told me that it was not able to resolve that symbol.  What did I do wrong? [<-CODE->]  __eou__	user	0	1	1	2
IG	truevines: it's a lombok method __eou__	agent	1	1	0	1
FD	 [<-LINK->]  __eou__	agent	1	1	0	1
FD	basically: the@Dataand@Getterannotations at the top of the class __eou__	agent	0	1	0	0
FD	you'll need the lombok plugin for intellij too, if you are messing with source __eou__	agent	1	1	0	1
GG	AlexDBlack: Thanks, Alex. __eou__	user	0	1	0	0

OQ	A further question.  I could not make/build the dl4j code base using IntelliJ.  For example, I tried to make the deeplearning4j-nn module, and received the follow error message: __eou__	user	0	1	1	2
CQ	truevines: did you follow the buildinglocally guide? __eou__	agent	0	1	0	0
FD	That gives an end to end description of the setup __eou__	agent	0	1	0	0
IG	Error:(22, 35) java: package org.nd4j.linalg.api.ndarray does not existError:(33, 31) java: cannot find symbolsymbol:   class INDArraylocation: class org.deeplearning4j.util.SummaryStatistics __eou__	user	0	1	0	0
FD	But I could build the dl4j-examples with no issues. __eou__	user	0	1	0	0
IG	You cant just import dl4j __eou__	agent	1	1	0	1
FD	Its a 4 repo project __eou__	agent	1	1	0	1
JK	Well duh __eou__	agent	0	1	0	0
FD	Thats maven central ;) __eou__	agent	1	1	0	1
FD	Big difference __eou__	agent	1	1	0	1
FD	Seems like you skipped reading half of the docs :/ __eou__	agent	1	1	0	1
FD	 [<-LINK->]  __eou__	agent	1	1	0	1
FD	Go through this first __eou__	agent	1	1	0	1
AE	Sorry about that.  I thought I could just download the codebase and build it. __eou__	user	0	1	0	0
PF	Thanks for the information. __eou__	user	0	1	0	0
IG	We dont have snapshots yet so you neef yo setup c code :D __eou__	agent	1	1	0	1
FD	I appreciate the effort but dl4j isnt just 1 codebase __eou__	agent	1	1	0	1
FD	Wee bit more complex than that :D __eou__	agent	1	1	0	1
PF	Thanks. __eou__	user	0	1	0	0

OQ	saudet: I did investigate that first but it seems that it doesn't really perform a sliding window, and then I'd have to convert each window to an indarray anyways which scares me __eou__	user	0	1	1	2
IG	crockpotveggies: well, it's kind of limited in what it can do, but it's fast __eou__	agent	1	1	0	1

OQ	Anyone can help see my question mentioned before? I set the iteration score listener. In 0.6.0, I can get the "INFO" of the iteration scores. But In 0.7.1, there is no such score INFO although I set the listener as well. __eou__	user	0	1	1	2
IG	AllenWGX: nothing changed thete __eou__	agent	1	1	0	1
FD	There __eou__	agent	1	1	0	1
FD	The only thing it would be is your logging __eou__	agent	1	1	0	1
FD	Check the commit logs yourself if you want __eou__	agent	1	1	0	1
UFAC	ok, I will check then. __eou__	user	0	1	0	0

OQ	I want to take compressed output from hidden layer of autoencoder.Some one suggested to use feedforward method for that but I'm not able to implement that.Pls help __eou__	user	0	1	1	2
IG	saurabhgangurde: literally theres' nothing else to do other than use feedforward... that gives you activations, which is exactly what you are asking for __eou__	agent	1	1	0	1
IG	AlexDBlack: <CODE> __eou__	user	0	1	0	0

IG	qq95538: Welcome! Here's a link to Deeplearning4j's Gitter Guidelines, our documentation and other DeepLearning resources online. Please explore these and enjoy! [<-LINK->]  __eou__	user	0	0	0	0
GG	thank you, raver120,  __eou__	agent	0	0	0	0
AC	I am reading deeplearning4j.org/quickstart,  __eou__	agent	0	0	0	0
PF	your advice is so kind. __eou__	agent	0	0	0	0

OP	Ok, the crux of my question lies here : DataSetIterator trainIter = new DataSetIterator(trainingDataSet,miniBatchSize); gives me compile error DataSetIterator is abstract, can't be instantiated __eou__	user	0	1	1	2
FD	So, I was willing to know what should I implement __eou__	user	0	1	0	0
JK	bikashg: How can I help someone who ignores me? :D __eou__	agent	0	1	0	0
JK	You ignore me and our docs __eou__	agent	0	1	0	0
JK	Not sure what else I can do for you here __eou__	agent	0	1	0	0
JK	:) __eou__	user	0	1	0	0
IG	DataSetIterator is an interface __eou__	agent	1	1	0	1
FD	I'm not sure what else you expect __eou__	agent	1	1	0	1
FD	I'm telling you exactly how to make your life easy __eou__	agent	1	1	0	1
FD	You will  end up rewriting half the stuff we already did for you in recordreaderdatasetiterator __eou__	agent	1	1	0	1
FD	We forced it to be 1 iterator for a reason __eou__	agent	1	1	0	1
FD	we decoupled parsing logic from dataset handling and ndarray creation __eou__	agent	1	1	0	1
FD	there's 1 billion reasons why that's a good idea __eou__	agent	1	1	0	1
FD	 [<-LINK->]  __eou__	agent	1	1	0	1
FD	150 lines of code __eou__	agent	1	1	0	1
FD	This looksreally hard __eou__	agent	1	1	0	1
FD	I mean no offense here I'm just not understanding what the resistance is __eou__	agent	1	1	0	1
FD	We already did the work for you __eou__	agent	1	1	0	1
UF	OK,  __eou__	user	0	1	0	0
AC	I will get started with reading DataVec. The only "resistance" is that my Input is not a CSV and on first sight,  __eou__	user	0	1	0	0
AE	it seemed to me that the only supported format was CSV __eou__	user	0	1	0	0

OQ	INDArray myArr = Nd4j.create(flat,shape,'c');    what does 'c' represent? __eou__	user	0	0	0	0
FD	and what is the difference between 'c' and 'f'? __eou__	user	0	0	0	0
FD	is there any material about this? __eou__	user	0	0	0	0
JK	 [<-LINK->]  __eou__	agent	0	0	0	0
JK	see this __eou__	agent	0	0	0	0
PA	yuimo123: it's general concept, C-ordering and Fortran ordering of elements within linear buffer __eou__	agent	0	0	0	0
FD	aka Column-major and Row-major __eou__	agent	0	0	0	0
FD	yes , i know. 'c' is c order ,and 'f' is f order __eou__	user	0	0	0	0
IR	why asked then? __eou__	agent	0	0	0	0
JK	:) __eou__	agent	0	0	0	0
JK	yuimo123: see [<-LINK->]  __eou__	agent	0	0	0	0
PF	thanks. __eou__	user	0	0	0	0
FD	raver119: i am read the examples of nd4j, and i saw this. just ask __eou__	user	0	0	0	0

OQ	Hi, everyone! I wanna to implement some missing functions in deeplearning4j (for example the multiplication operation in ElementWiseVertex). Is there a recommended way to do? Thank you! __eou__	user	0	1	1	2
IG	Oscarlight: Welcome! Here's a link to Deeplearning4j's Gitter Guidelines, our documentation and other DeepLearning resources online. Please explore these and enjoy! [<-LINK->]  __eou__	agent	1	1	0	1

OQ	i have still problem with understanding the batchsize. Let me explain, if i have 100 rows in train set and if i set batch size=100  means what? or setting batchsize=1 whta are the differences? i really still dont understand. __eou__	user	0	1	1	2
JK	K __eou__	agent	0	1	0	0
IG	So I'm going to ask you read a book now :D __eou__	agent	1	1	0	1
FD	 [<-LINK->] __eou__	agent	1	1	0	1
UF	ok __eou__	user	0	1	0	0
IG	 [<-LINK->] __eou__	agent	1	1	0	1
FD	Go through this chapter and come back __eou__	agent	1	1	0	1
FD	If you still have questions then we can talk __eou__	agent	1	1	0	1
FD	I'm biased but I also wrote a !book __eou__	agent	1	1	0	1
PF	thanks you very much __eou__	user	0	1	0	0
IG	More basic questions are answered in depth in the textbook __eou__	agent	1	1	0	1
UF	ok __eou__	user	0	1	0	0

OQ	Hi, how can i avoid score value being NaN during training? I think reporting NaN is undesired. Am i correct? __eou__	user	0	1	1	2
IG	!tuning __eou__	agent	1	1	0	1
IG	!tuning __eou__	agent	1	1	0	1
FD	Accuracy is low or network isn't learning? Start by reading [<-LINK->] and [<-LINK->]  __eou__	agent	1	1	0	1
JK	hmmm __eou__	agent	0	1	0	0
JK	If you want help from us prove to me your read our tuning docs first :D __eou__	agent	0	1	0	0
UF	ok __eou__	user	0	1	0	0
IG	hakmesyo: go through those steps  __eou__	agent	1	1	0	1
PF	:) __eou__	user	0	1	0	0
IG	to your hyper parameters and what you've tried __eou__	agent	1	1	0	1
UF	ok __eou__	user	0	1	0	0

OQ	where can i find resources to understand how dl4j works interally? __eou__	user	0	1	1	2
IG	depends what you are looking for... it's a huge projectare you trying to implement a new type of neural network or something? __eou__	agent	1	1	0	1

GG	hi __eou__	user	0	1	1	2
IG	v-mostafapour: Welcome! Here's a link to Deeplearning4j's Gitter Guidelines, our documentation and other DeepLearning resources online. Please explore these and enjoy! [<-LINK->]  __eou__	agent	0	1	0	0
OQ	I would like to use this code in java eclipse instead of  IntelliJ __eou__	user	0	1	0	0
FD	 [<-LINK->]  __eou__	user	0	1	0	0
IG	v-mostafapour: there's nothing stopping you __eou__	agent	1	1	0	1
FD	learn m2eclipse __eou__	agent	1	1	0	1
FD	We won't support you if something hits a wall though __eou__	agent	1	1	0	1
FD	We just don't use it __eou__	agent	1	1	0	1
FD	So we can't really help with troubleshooting weird edge cases __eou__	agent	1	1	0	1
FD	Beyond that follow traditional tutorials on the internet __eou__	agent	1	1	0	1
FD	We aren't anything unique as long as you're using a build system __eou__	agent	1	1	0	1
GG	thanks __eou__	user	0	1	0	0

OQ	I'm having trouble trying to run an example project in Eclipse using Maven. How should I set the Maven project's launch configuration? __eou__	user	0	1	1	2
IG	CubeMaster007: Welcome! Here's a link to Deeplearning4j's Gitter Guidelines, our documentation and other DeepLearning resources online. Please explore these and enjoy! [<-LINK->]  __eou__	agent	1	1	0	1
IG	There is nothing to set o_0 __eou__	agent	1	1	0	1
FD	If you are having problems it is likely related to being new to m2eclipse __eou__	agent	1	1	0	1

OQ	I am looking at the tsne and word2vec example. The code in TSNEStandardExample runs but does not plot anything at the end. The documentation on [<-LINK->] shows different code, ending in vec.lookupTable().plotVocab(tsne); which does not match what's in TSNEStandardExample. How do I get a plot of the result? __eou__	user	0	1	1	2
IG	bhomass: there’s 2 options: either render to UIServer, or save to file as csv __eou__	agent	1	1	0	1

IG	 [<-LINK->]  __eou__	user	0	1	1	2
OQ	agibsonccc: hi, my computer config is i3 cpu, and 8G ram. but when i run this example of  Word2VecSentimentRNN, it keeps in this state for a long time. does that mean my computer config not enough? __eou__	user	0	1	0	0
IG	yes __eou__	agent	1	1	0	1
FD	ram isn’t enough __eou__	agent	1	1	0	1
CQ	"i3"? __eou__	agent	0	1	0	0
IG	nvm cpu, ram is an issue here __eou__	agent	0	1	0	0
IG	yes __eou__	user	0	1	0	0
AE	That will take forever to run anythin g:D __eou__	agent	0	1	0	0
FD	ram too though __eou__	agent	0	1	0	0
AE	i bet pc is swapping :) __eou__	agent	0	1	0	0
IG	i asked u before, and you said you have run this in your lap, and it's 8G too ,hh __eou__	user	0	1	0	0
AE	Well it\'s "possible" __eou__	agent	0	1	0	0
AE	doesn't mean it's ideal :D __eou__	agent	0	1	0	0
IG	adam’s laptop is slightly more then 8g :) __eou__	agent	0	1	0	0
IG	My travel laptop is 24GB __eou__	agent	0	1	0	0
UF	ok,  __eou__	user	0	1	0	0

OQ	but Adam,  I have 1 million records (each has 10 time series), so that means I have to create 1 million files with 10 record in each . I don't think it is a good choice .... __eou__	user	0	1	1	2
IG	That's what I do too (for other reasons) and it gives me just a few hundred files (batches of 150 examples) __eou__	agent	1	1	0	1
FD	(note that I need multiple files for a single example, multiple inputs and outputs, but that shouldn't matter otherwise) __eou__	agent	1	1	0	1
GG	thanks Ede,  __eou__	user	0	1	0	0

OQ	I am trying to look into dl4j core source so I figure out how to use UiConnectionInfo. mvn download sources does not seem to work. is dl4j core source available? __eou__	user	0	1	1	2
FD	it would be helpful if someone at least put up a example that displays a plot on UiSever from beginning to end __eou__	user	0	1	0	0
FD	otherwise, its time to give up __eou__	user	0	1	0	0
IG	bhomass: i’ve posted you a link few hours ago __eou__	agent	1	1	0	1
FD	link to repo __eou__	agent	1	1	0	1
FD	 [<-LINK->]  __eou__	agent	1	1	0	1
FD	and download sources work as well __eou__	agent	1	1	0	1
FD	it’s kinda requirement __eou__	agent	1	1	0	1
UF	ok,  __eou__	user	0	1	0	0
IG	it’s right there at maven __eou__	agent	0	1	0	0

OQ	hi i use autoencoder to do feature processing. i get the model. but i find the input vector[0.000001, 0.3, 0.1143, 0.1786, 0.0, 0.0, 0.0, 1.0, 0.1257]is converted[0.00, 0.30, 0.11, 0.18, 0.00, 0.00, 0.00, 1.00, 0.13]by this methodINDArray features = Nd4j.create(featureData);if i want to keep more decimal what should I do? __eou__	user	0	1	1	2
IG	it's just formatting on toString __eou__	agent	1	1	0	1
FD	check with getDouble if you want __eou__	agent	1	1	0	1
UF	ok  __eou__	user	0	1	0	0

OQ	raver119: @agibsoncccOne Q. Today evening in my talk I'm planning to state that DL4J is the only FW capable of training NN in Jeff Dean Style Parameter Averaging on ApacheSpark (+ GPU support +support for all sorts of NN topologies) Is this correct? IMHO TensorFrames doesn't support parallel Parameter Averaging , correct? __eou__	user	0	1	1	2
IG	yup __eou__	agent	1	1	0	1
FD	so tensorframes only allows ETL __eou__	agent	1	1	0	1
FD	The main thing it had going for it was the catalyst compiler for tensorflow ops __eou__	agent	1	1	0	1
FD	Italsohasn't seem a commit since august __eou__	agent	1	1	0	1
FD	We also support configuring everything from a spark job __eou__	agent	1	1	0	1
FD	Tensorframes for their JNI support used javacpp (which we maintain) __eou__	agent	1	1	0	1
FD	So main differences: Community and Distributed __eou__	agent	1	1	0	1
PF	Thanks a lot@agibsonccc __eou__	user	0	1	0	0
CC	sure :D __eou__	agent	0	1	0	0
IG	also tensorframes is based on dataframes, so no variable length data (images, time series etc) afaik __eou__	agent	1	1	0	1
PF	right __eou__	agent	0	1	0	0

OQ	Hi! I wanted to know what exactly the score of ScoreIterationListener specify? Is it the value cost function ? Because what I understand is the lower the score the better. So is it the cost function value or something else ? __eou__	user	0	1	1	2
IG	anandundavia: yes cost __eou__	agent	1	1	0	1
FD	usually for a given batch __eou__	agent	1	1	0	1
UF	Okay  __eou__	user	0	1	0	0

OQ	When producing feature maps for convolution layer from previous pooling layer, to  my understanding, it's a full connection between all feature maps in pooling layer and one in convolution layer. Is this the groundtruth? __eou__	user	0	0	0	0
FD	It is according to " [<-LINK->] " __eou__	user	0	0	0	0

GG	Hi guys how are you __eou__	user	0	0	0	0

OQ	How to get Layer instance of a specific vertex in ComputationGraph from custom BaseInputPreProcessor... __eou__	user	0	0	0	0
JK	? __eou__	user	0	0	0	0
FD	I want to simply reach the weights of a layer (vertex) from another layer (vertex) during training... __eou__	user	0	0	0	0

OQ	hey, I'm trying to import a model from keras, which seems to be working, but I don't really understand how to include the json and hdf file in the output jar. I put them in a resources folder that's a resource root and they are present at the root of the jar file, but I get a no file found exception __eou__	user	0	0	0	0

OQ	I\'m trying to use the video Classification example and have created a directory with mp4 videos (videos created with JavacV <CODE> __eou__	user	0	0	0	0
FD	is there an mp4 codec that is recommended, or will any of the mp4 codec options suffice? __eou__	user	0	0	0	0

OQ	I try to use  MatlabRecordReader but I can't understand how it works, anybody can explain me please? __eou__	user	0	0	0	0

OQ	i spotted a pretrain boolean parameter in configuration __eou__	user	0	0	0	0
FD	does this turn on Greedy Layer-Wise Unsupervised Pretraining for FFNN/RNN/CNN? __eou__	user	0	0	0	0

OQ	Is the parameter "learningRateScoreBasedDecayRate" the same as learningRateDecayPolicy(LearningRatePolicy.Score).lrPolicyDecayRate ? __eou__	user	0	0	0	0

OQ	Hi guys, with Deeplearning4J can I reproduce the results achieved articles about artistic style transfer? I found several implementation on Tensorflow (e.g. [<-LINK->] ). Is there any similar example or tutorial also for Deeplearning4j? __eou__	user	0	0	0	0

OQ	I am trting to load a saved keras model, and the backend is tensorflow. My environment is eclipse, java 1.8, CPU. this is my code:https://gist.github.com/kuluofenghun/581c8be86031bbe28112a3b91eb66214.js and this is my pom filehttps://gist.github.com/kuluofenghun/8fcdcaebffb84bd0b8a8b07afb662b40.jsBut it failed.  the error information is :Exception in thread "main" java.lang.NoClassDefFoundError: org/nd4j/shade/jackson/core/type/TypeReferenceI also try to use the git source. there is the same error in the deeplearning4j-modelimport project:The import org.nd4j.shade.jackson.core.type.TypeReference cannot be resolvedThe import org.nd4j.shade.jackson.databind.ObjectMapper cannot be resolvedHow to solve this question? __eou__	user	0	0	0	0
FD	AlexDBlack: I have correct my pom file and remove the  nd4j-jackson in my pom filebut the error is stillException in thread "main" java.lang.NoClassDefFoundError: org/nd4j/shade/jackson/core/type/TypeReferenceI also tried the git source of dl4j, the are the same error in the project deeplearning4j-modelimport:The import org.nd4j.shade.jackson.core.type.TypeReference cannot be resolved __eou__	user	0	0	0	0

OQ	I have a quick question about [<-LINK->] : Why is the prefetchBuffer set to 24 by default when the javadocs on prefetchBuffer says it should generally be the same as the number of workers? 24 seems really high with only 4 workers __eou__	user	0	0	0	0

GG	Hi Guys __eou__	user	0	0	0	0
OP	I've realized that my /tmp folder gets filled with tons of 'restoreXXXX' files, that I guess come from the use of the ModelSerializer.restoreMultiLayerNetwork(path) function. __eou__	user	0	0	0	0
OQ	Is there a way to regulate that? __eou__	user	0	0	0	0
FQ	app86: we can look in to that - could you file an !issue ? __eou__	agent	0	0	0	0
AE	shouldn’t be. __eou__	agent	0	0	0	0
FD	i usually call deleteOnExit __eou__	agent	0	0	0	0
FD	but i’ll look into that now __eou__	agent	0	0	0	0
JK	ah __eou__	agent	0	0	0	0
FD	that’s not me __eou__	agent	0	0	0	0
FQ	that’s probably earlystopping you use there? __eou__	agent	0	0	0	0
CC	I used early stopping for the trainning, yes __eou__	user	0	0	0	0
PF	right __eou__	agent	0	0	0	0
AC	do as adam said __eou__	agent	0	0	0	0
AC	file an issue __eou__	agent	0	0	0	0
UF	Ok __eou__	user	0	0	0	0
AC	just file an issue, and we’ll sort it out after release hits. it’s not really a big deal anyway __eou__	agent	0	0	0	0
UF	Ok. __eou__	user	0	0	0	0

OQ	I want to solve the conflict, can I load libgomp from jars by modify nd4j's source code? __eou__	user	0	1	1	2
FD	if don't care the system, how to use javacpp load library from specify path before load from /usr/lib64 __eou__	user	0	1	0	0
CQ	Wouldn't setting LD_PRELOAD work? __eou__	agent	0	1	0	0
CQ	try building libnd4j from sources? __eou__	agent	0	1	0	0
IG	in worst case you'll just remove few pragmas __eou__	agent	1	1	0	1
FD	probably around declare simd __eou__	agent	1	1	0	1
IG	liulhdarks: JavaCPP does that by default, something else is loading system libraries __eou__	agent	1	1	0	1
FQ	Wether I can remove the gomp from platform.preload in the linux-x86_64-nd4j.properties? __eou__	user	0	1	0	0
PF	but yes, like@agibsoncccsays using LD_LIBRARY_PATH and/or LD_PRELOAD should force whatever to use what you want ;) __eou__	agent	0	1	0	0
UF	ok  __eou__	user	0	1	0	0

OQ	I have question, I checkout the tag version "deeplearning4j-0.7.0" from git hub yesterday, after import it into IDEA and resolve maven dependencies, I still see there are many code error, have I missed something? __eou__	user	0	1	1	2
CQ	FlyingPiggyKing: wait what? __eou__	agent	0	1	0	0
CQ	Are you trying to build from source? __eou__	agent	0	1	0	0
JK	No where in our docs do we tell you to do that :D __eou__	agent	0	1	0	0
IG	Use maven central please __eou__	agent	1	1	0	1
FD	dl4j has 4 projects including c code you need to build from source __eou__	agent	1	1	0	1
FD	I wouldn't suggest trying that __eou__	agent	1	1	0	1
FD	Especially if you're new __eou__	agent	1	1	0	1
NF	I just want to dig into the code, see how it works, but I see many code error, like some function is missing... __eou__	user	0	1	0	0
CC	FlyingPiggyKing: yeah don't do that __eou__	agent	0	1	0	0
JK	like at all __eou__	agent	0	1	0	0
IG	use intellij to download the source __eou__	agent	1	1	0	1
FD	and run it in the debugger if you want to do that __eou__	agent	1	1	0	1
FD	otherwise you have to build from source __eou__	agent	1	1	0	1
FD	Like I said you have to build 4 projects to even get to dl4j __eou__	agent	1	1	0	1
FD	You sound completely new to a lot of this __eou__	agent	1	1	0	1
FD	I wouldn't suggest digging in unless you have to __eou__	agent	1	1	0	1
FD	Of course you'r going to have errors __eou__	agent	1	1	0	1
FD	You need to build the other libraries first __eou__	agent	1	1	0	1
FD	Don't do it unless you have a compelling reason to __eou__	agent	1	1	0	1
FD	if you want to just explore don't clone dl4j __eou__	agent	1	1	0	1
IG	FlyingPiggyKing: you can view the source from intellij using the maven release, just ctrl+b on the various classes, and you can read through them therewithout the headaches associated with  building from source :) __eou__	agent	1	1	0	1
FQ	AlexDBlack: so you mean let idea to decompile the code from the jar? __eou__	user	0	1	0	0
CC	no, not decompile. download sources __eou__	agent	0	1	0	0
FD	FlyingPiggyKing: I already said the source is in maven central __eou__	agent	0	1	0	0
FD	those are on maven central too __eou__	agent	0	1	0	0
PF	AlexDBlack: ok, got __eou__	user	0	1	0	0
AC	let me try __eou__	user	0	1	0	0
PF	yes, it work for some of the class, like MultiLayerNetwork.java, I can click on the link on the top bar of IDEA, it can download it, while for some class like MultiLayerConfiguration.class, seems like the class is inconsistent with the downloaded source code. __eou__	user	0	1	0	0
FD	FlyingPiggyKing: intellij is usually weird about that I wouldn't pay too much attention to it __eou__	agent	0	1	0	0
FD	That's usually because of source code comments and the like __eou__	agent	0	1	0	0
CQ	it might also be lombok annotation maybe, expanded in binaries but not source? __eou__	agent	0	1	0	0
FD	anyway, not a concern really __eou__	agent	0	1	0	0
FD	there some minor error in the source code, like the logger declaration is missing, I see@Slf4j, this maybe the reason __eou__	user	0	1	0	0
IR	FlyingPiggyKing: that's lombok like alex mentioned __eou__	agent	0	1	0	0
PF	got it, very thanks! __eou__	user	0	1	0	0

OQ	agibsonccc: how can I use wordVectors in seq2seq?                                                                       input_word.put(new INDArrayIndex[]{NDArrayIndex.point(i), NDArrayIndex.all(), NDArrayIndex.point(j)}, vector );     the error:org.nd4j.linalg.api.buffer.BaseDataBuffer$2 cannot be cast to org.bytedeco.javacpp.DoublePointer __eou__	user	0	0	0	0
CQ	gguogguo11: Could you give a full stack trace? I know you can't use gist in china so please use tool.lu if possible __eou__	agent	0	0	0	0
FD	Screenshots aren't usually good either __eou__	agent	0	0	0	0
FD	Tough to look at __eou__	agent	0	0	0	0

OQ	AlexDBlack: is there a way to calculate how much time it would take for Word2Vec to fit on some data? __eou__	user	0	1	1	2
FD	or even monitor what's going on? __eou__	user	0	1	0	0
FD	The reason why I am asking is because it has been more than 1 hour 20 minutes since the last log entry of  "Starting vocabulary building..." and 1 hour since it finished iterating over the data. PS: There were 58754 sentences for training the model __eou__	user	0	1	0	0
IG	KonceptGeek: with a small data set like that, it shouldn't take longyou can add a VectorsListener instance to track progress... it should also log plenty of infobtw,  __eou__	agent	1	1	0	1
IG	AlexDBlack: DL4J 0.7.0 with nd4j-native __eou__	user	0	1	0	0
FD	There's Factorie and JSAT __eou__	user	0	1	0	0
FD	both of them are regularly updated __eou__	user	0	1	0	0
IG	KonceptGeek: I'd suggest asking @raver119 about the word2vec performance issues (he should be online in about 6 hours maybe?)fwiw it should be significantly faster than 0.6.0, and your data isn't largefeel free to open an issue though with details and configuration - that might make things easier for us __eou__	agent	1	1	0	1
AE	Sure@AlexDBlack. BTW, each sentence is a pretty big (almost a complete email/document) so that could possibly be slowing things down. And it's running on an 8core CPU. __eou__	user	0	1	0	0

OQ	Hi, there. I am new to dl4j and trying to run it on an spark on yarn cluster. Is there any configuration to do with the cluster? I cannot find any document about it. __eou__	user	0	1	1	2
IG	Marcteen:  [<-LINK->]  __eou__	agent	1	1	0	1
FD	not sure how you missed this :D __eou__	agent	1	1	0	1
FD	we mention yarn and the like right in there __eou__	agent	1	1	0	1
FD	including the memory configuration __eou__	agent	1	1	0	1
FD	our !examples have spark in them as well __eou__	agent	1	1	0	1
IG	Our latest examples available here: [<-LINK->]  __eou__	agent	1	1	0	1
GG	agibsonccc: Thanks.  __eou__	user	0	1	0	0
IG	It's just a spark job really __eou__	agent	1	1	0	1
FD	It's nothing different than what you already do __eou__	agent	1	1	0	1
FD	dl4j-spark is all you need __eou__	agent	1	1	0	1
FD	you can look at our examples for that stuff __eou__	agent	1	1	0	1

OQ	agibsonccc: You are so kind. Actually I am not very familiar with Maven. I build an Maven project with idea and add dl4j-spark to pom like<dependency>\n      <groupId>org.deeplearning4j</groupId>\n      <artifactId>dl4j-spark_${scala.compat.version}</artifactId>\n      <version>${dl4j.version}</version>\n    </dependency>And them I write an scala object which is a copy from dl4j-example with spark. After idea complete the dependency resolving, all the class need jar seems not ready for import(such as org.deeplearning.nn.xxx). Should I add some extra dependency such as dl4j-core?(I found it in pom of dl4j-example) __eou__	user	0	1	1	2
CQ	have you tried just following our quick start and importing the exampels as is? __eou__	agent	0	1	0	0
CC	oops I made mistakes..hhh __eou__	user	0	1	0	0
FQ	agibsonccc: Is it ok if I just copy the dependencies from the dl4j-spark-exmaple to my own application pom? __eou__	user	0	1	0	0
IG	more or less should have everything __eou__	agent	1	1	0	1
FD	I would try to learn maven though __eou__	agent	1	1	0	1
FD	at least learn how to interpret what you're reading __eou__	agent	1	1	0	1
FD	so you don't make a mistake __eou__	agent	1	1	0	1
GG	agibsonccc: Thanks for your reply.  __eou__	user	0	1	0	0

OQ	Hi, I want to use DL4J to train my model, but my big concern is about training speed. I just read an article [<-LINK->] , seems DL4J is kinda slow. I am wondering whether this article is misleading somehow? __eou__	user	0	1	1	2
IG	Lancer66: that stuff is always out of date __eou__	agent	1	1	0	1
FD	I would run your own benchmark __eou__	agent	1	1	0	1
IG	Lancer66: all that stuff changes each and every release __eou__	agent	1	1	0	1
CQ	When was the paper even written? o_0 __eou__	agent	0	1	0	0
IG	 [<-LINK->]  __eou__	user	0	1	0	0
IG	Lancer66: Welcome! Here's a link to Deeplearning4j's Gitter Guidelines, our documentation and other DeepLearning resources online. Please explore these and enjoy! [<-LINK->]  __eou__	agent	0	1	0	0
FQ	October 2016? not sure __eou__	user	0	1	0	0
CC	hmm..may __eou__	agent	0	1	0	0
AC	Run your own benchmark __eou__	agent	1	1	0	1
FD	If you do make sure to pre save the data: [<-LINK->]  __eou__	agent	1	1	0	1
UF	OK,  __eou__	user	0	1	0	0

OQ	Hi, I am willing to contribute to deeplearning4j-nlp-parent module, especially I am interested in allowing custom windows.Currently, DL4J implements sliding windows of given context size. I want to provide a factory for windows, and therefore an interface for Windows, so that one can provide its own implementation of a window. Is there any suggestion to bootstrap me / traps to avoid in the design of how DL4J handles windows please ? __eou__	user	0	1	1	2
JK	cgravier: I worked on a previous implementation of this __eou__	agent	0	1	0	0
CQ	you're talking nlp right? __eou__	agent	0	1	0	0
CC	agibsonccc: Yes I am :) __eou__	user	0	1	0	0
IG	 [<-LINK->]  __eou__	agent	1	1	0	1
FD	Poke around in here __eou__	agent	1	1	0	1
FD	see also the files in the same directory __eou__	agent	1	1	0	1
FD	if you can improve on it please do __eou__	agent	1	1	0	1
FD	We haven't used this in a while so I would LOVE seeing some updates to this __eou__	agent	1	1	0	1
FD	even a rewrite is fine __eou__	agent	1	1	0	1
GG	Thanks,  __eou__	user	0	1	0	0
IG	the unit tests might be helpful though __eou__	agent	0	1	0	0
FD	yeah  I implemented this back in the days of yore __eou__	agent	0	1	0	0
FD	definitely needs some attention :D __eou__	agent	0	1	0	0
AC	Yes, I think I could be best to fork master and try to reintroduce the changes and modify at the same time for improvment if any __eou__	user	1	1	0	1
IG	I originally used this for moving window MLP stuff __eou__	agent	0	1	0	0
PF	I am convinced it does 0;-) __eou__	user	0	1	0	0
PF	thanks for contributing happy to answer questions about the older impl __eou__	agent	0	1	0	0
GG	Well, that's me who is thankful :) I'll will explore the links and see how things goes __eou__	user	0	1	0	0

OQ	agibsonccc: , Can you look at the GenderDetection example code that I uploaded few days back for your review? Please let me know if I need to add more useful information into it to make it compatible with dl4j-examples. __eou__	user	0	1	1	2
CQ	gks141270: I merged it already? __eou__	agent	0	1	0	0
CQ	Did you do another commit? __eou__	agent	0	1	0	0
FQ	No, I didn't. Is it available in dl4j-examples now? __eou__	user	0	1	0	0
IG	 [<-LINK->]  __eou__	agent	1	1	0	1
JK	Oh.. __eou__	user	0	1	0	0
PF	Great. I am happy to see it __eou__	user	0	1	0	0

OQ	I made an app with dl4j and I want to deploy it on weblogic which is installed on a linux machine __eou__	user	0	0	0	0
CQ	enache2004: should be straightforward what are you running in to? __eou__	agent	0	0	0	0
IG	it complains about java.lang.UnsatisfiedLinkError: no jnind4j in java.library.path __eou__	user	0	0	0	0
CQ	just use nd4j-native-platform then? __eou__	agent	0	0	0	0
AC	make sure your dependencies are up to date too __eou__	agent	0	0	0	0
CC	I use a previous version of dl4j 3.9 __eou__	user	0	0	0	0
JK	O_O __eou__	agent	0	0	0	0
CQ	yup we've had 5-6 releases since then? __eou__	agent	0	0	0	0
FQ	maybe more __eou__	agent	0	0	0	0
AC	I would like to test it that version because everything was fine on my machine __eou__	user	0	0	0	0
NF	I know..sorry __eou__	user	0	0	0	0
IG	we aren't liable for versions before this __eou__	agent	0	0	0	0

OQ	I still don't know why I get this: Warning: class 1 was never predicted by the model. __eou__	user	0	0	0	0
IR	again, can you confirm that you had class 1 in your test set? __eou__	agent	0	0	0	0
FD	I verified each step and my training data path seems ok __eou__	user	0	0	0	0
FD	yes..i have two folders __eou__	user	0	0	0	0
FD	is face __eou__	user	0	0	0	0
FD	no face __eou__	user	0	0	0	0
PA	enache2004: track your data input pipeline. there were many changes there. __eou__	agent	0	0	0	0
JK	 [<-CODE->]  __eou__	user	0	0	0	0
CQ	enache2004: how about the model params? anything funky there? __eou__	agent	0	0	0	0
FQ	for nueral net ? __eou__	user	0	0	0	0
PA	yes __eou__	agent	0	0	0	0
IR	everything is the same __eou__	user	0	0	0	0
JK	that's strange __eou__	user	0	0	0	0
PA	switching to 3.9 and works perfect __eou__	user	0	0	0	0
FD	this is my model __eou__	user	0	0	0	0
PA	enache2004: please don't do that __eou__	agent	0	0	0	0
FD	use !gist __eou__	agent	0	0	0	0
FD	To use gist: paste your code/exception/large output log into [<-LINK->] , click 'Create Secret Gist' and paste URL link here __eou__	agent	0	0	0	0
JK	I like how is formatting :D __eou__	user	0	0	0	0
JK	ok __eou__	user	0	0	0	0
JK	 [<-LINK->]  __eou__	user	0	0	0	0
FD	aha, another change applied is xavier weight init __eou__	agent	0	0	0	0
FD	originally it was wrong __eou__	agent	0	0	0	0
FD	now it's fixed __eou__	agent	0	0	0	0
FD	original implementation is called XAVIER_LEGACY __eou__	agent	0	0	0	0
FD	.weightInit(WeightInit.XAVIER) <----- this thing __eou__	agent	0	0	0	0
FQ	so ...I will changed to ? __eou__	user	0	0	0	0
FD	legacy? __eou__	user	0	0	0	0
FD	the other think that I noticed is StandardScaler which is deprecated __eou__	user	0	0	0	0
FD	could this change my results ? __eou__	user	0	0	0	0
IR	not sure what was changed for StandardScaler... __eou__	agent	0	0	0	0
FD	i mean it's just new implementation available, but don't know what was wrong with original __eou__	agent	0	0	0	0
FQ	I don't know what to follow __eou__	user	0	0	0	0
FD	to spend time to check if the latest version of dl4j has the native libraries fixed for linux __eou__	user	0	0	0	0
FD	or to keep my 3.9 version and investigate the part with java.library.path __eou__	user	0	0	0	0

OQ	Hello everyone ! Im also new to DL4J, tried some stuff, read about it and really like it :) . But what im currently struggling with is how to enable multi label data input in DL4J (an useful example would be tag prediction from an image) . For inputs with a single label i used the PathLabelGenerator, which was fine. Since Google and reading the docs did not help much (apart from redirecting to gitter :P ), i decided to ask here. __eou__	user	0	1	1	2
IG	Funny, someone else asked a very similar question a while ago about predicting multiple classes __eou__	agent	0	1	0	0
FD	I think the only way is to take the n classes with the highest probabilities after the softmax step __eou__	agent	1	1	0	1
FD	Maybe have a threshold on minimum probability and take all the classes with at least that probability __eou__	agent	1	1	0	1
FD	But I take it you want to assign multiple labels to examples during training time. No idea how that would work honestly. __eou__	agent	1	1	0	1
FD	Except maybe copying the examples that have multiple labels, one copy for every label you want to associate it with __eou__	agent	1	1	0	1
FQ	Do you mean using a PathLabelGenerator and having a path for each of the labels? __eou__	user	0	1	0	0
IG	CHemauer: I can't think a clean way to do that with the current built-in functionalityopen a github issue in datavec with your use case (i.e., where the labels are coming from - flat CSV? Map<URI,?>, etc) and we'll see what we can do __eou__	agent	0	1	0	0
FD	 [<-LINK->]  __eou__	agent	0	1	0	0
UF	Ok  __eou__	user	0	1	0	0

OQ	Is there an easy way to feed submats into a FFN and act on the parent image based on the prediction without having to write to disk?All the examples just show iterator examples. Do I have to manually write out the submats to create a DataSet/iterator? __eou__	user	0	1	1	2
CQ	araymer: are you talkign about with using javacv? __eou__	agent	0	1	0	0
IG	Yes __eou__	user	0	1	0	0
IG	You may want to look at NativeImageLoader __eou__	agent	1	1	0	1
FD	which wraps javacv __eou__	agent	1	1	0	1
CQ	Have you seen that already? __eou__	agent	0	1	0	0
IG	No,  __eou__	user	0	1	0	0
IG	araymer:  [<-LINK->]  __eou__	agent	0	1	0	0

OQ	Hi I am having a little bit of trouble setting up all of the dependencies for spark. With this import line: import org.deeplearning4j.spark.impl.paramavg.ParameterAveragingTrainingMaster; __eou__	user	0	1	1	2
IG	anchitkolla: make sure all your dl4j versions are the same first of all __eou__	agent	1	1	0	1
CQ	You saw our !examples right? __eou__	agent	0	1	0	0
IG	Our latest examples available here: [<-LINK->]  __eou__	agent	1	1	0	1
IG	Those has the pom.xmls you need __eou__	agent	1	1	0	1
FD	Usually it's just dl4j-spark __eou__	agent	1	1	0	1
FD	with the right scala version __eou__	agent	1	1	0	1
FD	dl4j-spark_2.10 or dl4j-spark_2.11 __eou__	agent	1	1	0	1
NF	yeah all of my spark import statements work except for that line. I am getting cannot resolve "paramavg".  __eou__	user	0	1	0	0

GG	Hi, one quick question :) __eou__	user	0	1	1	2
OQ	you run UIExample from IntelliJ Idea __eou__	user	0	1	0	0
FD	as Java application __eou__	user	0	1	0	0
FD	or Maven something? __eou__	user	0	1	0	0
CQ	what do you mean? __eou__	agent	0	1	0	0
IG	I open the UIExample.java file __eou__	user	0	1	0	0
FD	all good __eou__	user	0	1	0	0
FD	I go run as Java application __eou__	user	0	1	0	0
FQ	or I need to do do something like maven package? __eou__	user	0	1	0	0
IG	Run as java application __eou__	agent	1	1	0	1
GG	ok, tnx! __eou__	user	0	1	0	0

OQ	Thanks Alex. Actually my data are stored in a database , and I planed to  load and convert them to CSV files so that I could use D4J built-in DataIterator, but it is not feasible to create a million files , so I am wondering there are other built-in methods for this  :) __eou__	user	0	1	1	2
CQ	if you have data in database, why would you need csv? __eou__	agent	0	1	0	0
CQ	Because we don't have a JDBC record reader yet? __eou__	agent	0	1	0	0
JK	:D __eou__	agent	0	1	0	0
CQ	but he can read his data on his own, and just pass it via one of existing DataSetIterators that take jvm-originated data? __eou__	agent	0	1	0	0
FD	we have bunch of those __eou__	agent	0	1	0	0
IG	I was just trying to follow the tutorial . you know , I am new to D4J , so I am not familiar with how to create a custom DataSetIterator , so I started from the tutorial __eou__	user	0	1	0	0
IG	right but JDBC straight from the source would be more straightforward :D __eou__	agent	1	1	0	1
FQ	Is there any sample for loading data from database and put into RNN  ?@raver119@agibsonccc __eou__	user	0	1	0	0
IG	CSV is also the best tested __eou__	agent	1	1	0	1

OQ	have you got a code example which simply has working code for tsne plot on word2vec output? __eou__	user	0	0	0	0
FD	the document only has snippet __eou__	user	0	0	0	0
CQ	code for? __eou__	agent	0	0	0	0
FD	for single method call? __eou__	agent	0	0	0	0
OP	and the TSNEStandardExample.java does not plot __eou__	user	0	0	0	0
JK	i’ve already pointed you to method you need __eou__	agent	0	0	0	0
FD	like TSNEStandardExample.java, except one that actually put up a plot __eou__	user	0	0	0	0
JK	there’s nothing more needed from you __eou__	agent	0	0	0	0
NF	so you don't have such an example code __eou__	user	0	0	0	0

OQ	So I was having trouble finding out what that int array that used to be returned for that old getGameScreen. even was, there was no info about it on their site, so it\'s a little hard for me to figure out what I should do to get it into the correct format.  So I tried just converting to an int array (because that\'s what it expects) but it\'s complaining about "Mis matched lengths" __eou__	user	0	1	1	2
OQ	do I need to scale it somehow so it's equal size? __eou__	user	0	1	0	0
CQ	i can’t read your mind, sorry. give full exception as !gist please :) __eou__	agent	0	1	0	0
IG	To use gist: paste your code/exception/large output log into [<-LINK->] , click 'Create Secret Gist' and paste URL link here __eou__	agent	0	1	0	0
AC	Will do, one sec. Appreciate the patience. __eou__	user	0	1	0	0
IG	 [<-LINK->]  __eou__	user	0	1	0	0
NF	Oh shoot, my bad I used public. Won't do that again. __eou__	user	0	1	0	0
GG	that doesnt matters __eou__	agent	0	1	0	0
JK	so __eou__	agent	0	1	0	0
IG	exception is at the bottom __eou__	user	0	1	0	0
IG	one thing looks like a hint __eou__	agent	1	1	0	1
FD	i guess your byte[] length is 1440000 __eou__	agent	1	1	0	1
FD	and expected int[] length is  is 360000 __eou__	agent	1	1	0	1
FD	which is 1440000 / 4 (sizeof int)  = 360000 __eou__	agent	1	1	0	1
CQ	what their documentation says? :) __eou__	agent	0	1	0	0
IG	 [<-LINK->]  __eou__	user	0	1	0	0
FD	not crazy specific there __eou__	user	0	1	0	0
CQ	InMemoryLookupTable.plotVocab needs UIConnection argument. where do I find examples for that? __eou__	agent	0	1	0	0
NF	just says it's a byte array is all, and the previous api was just returning an int[] when you called getGameScreen() (no longer there), but I can't find any info on what that was either __eou__	user	0	1	0	0
AE	raver119: So that 1440000 number is = to the number of pixles in an 800x600 image, which is the resolution i'm running the game __eou__	user	0	1	0	0
JK	aha __eou__	agent	0	1	0	0
CQ	so that’s probably rl4j expects lower resolution? __eou__	agent	0	1	0	0
PF	possible... I didn't touch the resolution though so that'd be strange __eou__	user	0	1	0	0
FD	I suppose I could step through and figure out where that 36000 number is coming from __eou__	user	0	1	0	0
IG	from line 72 __eou__	agent	0	1	0	0
FD	observationSpace = new ArrayObservationSpace<>(new int[]{game.getScreenHeight(), game.getScreenWidth(), 3}); __eou__	agent	0	1	0	0
FD	i guess those options should be pr propagated to dl4j level __eou__	agent	0	1	0	0
IG	raver119: Okay, was having workspace issues... back at it now.  So the issue is that the ind array is totally different for what you said it's expecting there, and the screen_buffer __eou__	user	0	1	0	0
FD	what it's expecting is a shape of 800,600, 3 in an ndarray __eou__	user	0	1	0	0
FD	what it's getting is a 1,360000 __eou__	user	0	1	0	0

OP	[ERROR] Failed to execute goal org.apache.maven.plugins:maven-enforcer-plugin:1.4.1:enforce (enforce-default) on project dl4j-examples: Some Enforcer rules have failed. Look above for specific messages explaining why the rule failed. -> [Help 1] __eou__	user	0	1	1	2
IG	xtuyaowu: Welcome! Here's a link to Deeplearning4j's Gitter Guidelines, our documentation and other DeepLearning resources online. Please explore these and enjoy! [<-LINK->]  __eou__	agent	0	1	0	0
CQ	xtuyaowu: what are you trying to do? __eou__	agent	0	1	0	0
IG	You shouldn't get that by default.  __eou__	agent	1	1	0	1
IG	i feel "building from source" attempt... __eou__	agent	0	1	0	0
AE	probably :D __eou__	agent	0	1	0	0
IG	I see "dl4j-examples" though __eou__	agent	0	1	0	0

IG	I'm training a dnn + cnn model. The F1 score is around 50. But there are some warning that some classes are never predicted. __eou__	user	0	1	1	2
FD	i did a quite check. I guess that there are around 50% of training data is labeled as type A. There are 5 types. __eou__	user	0	1	0	0
OQ	shall i create the dataset which is perfect balanced for 5 types? __eou__	user	0	1	0	0
CQ	What do you mean "dnn + cnn" model? __eou__	agent	0	1	0	0
CQ	If you trained a conv net say that in plain english :D __eou__	agent	0	1	0	0
IG	Beyond that yes, minibatches should always be balanced __eou__	agent	1	1	0	1
FD	The intuition for minibatch learning comes from statistics __eou__	agent	1	1	0	1
FD	If you have a minibatch it should ideally be as close to representative of your whole population as possible __eou__	agent	1	1	0	1
CC	I mean danse layer + cnn. I used wrong word, i guess.... __eou__	user	0	1	0	0
IG	The reason I ask about your model, is because batch size largely depends on dimensions of the data and kind of problem as well as number of labels __eou__	agent	0	1	0	0
FD	Then say "conv net" :D __eou__	agent	0	1	0	0
FD	so depending on how big your images are you could be like mnist where 1k is a good idea (small dimensions) or 32/64 like imagenet __eou__	agent	0	1	0	0
FD	the label distribution will come down to batch size __eou__	agent	0	1	0	0
AC	Ok. I merged a csv data and image data 100x100 pixel __eou__	user	0	1	0	0
IG	but as evenly distributed as you can get would be better __eou__	agent	0	1	0	0
FD	make sure to check our !tuning guide __eou__	agent	0	1	0	0
CQ	Accuracy is low or network isn't learning?  __eou__	agent	0	1	0	0
IG	 and [<-LINK->]  __eou__	agent	0	1	0	0
NF	I read it, but want to learn more, for example about batch balancing __eou__	user	0	1	0	0
PF	thanks for the answer __eou__	user	0	1	0	0

GG	Hello~just 1 question __eou__	user	0	1	1	2
OQ	How can I contribute to document translation __eou__	user	0	1	0	0
JK	? __eou__	user	0	1	0	0
JK	you’re welcome :) __eou__	agent	0	1	0	0
GG	First of all - thank you for even offering. __eou__	agent	0	1	0	0
CQ	What language? __eou__	agent	0	1	0	0
IG	I hope to contribute korean translation __eou__	user	0	1	0	0
PF	oh my god yes __eou__	agent	0	1	0	0
IG	so it's just github pages __eou__	agent	1	1	0	1
FD	 [<-LINK->]  __eou__	agent	1	1	0	1
FD	Here's our korean docs right here __eou__	agent	1	1	0	1
PF	1 thing that would be IMMENSELY helpful would be if you could even just update our quickstart __eou__	agent	0	1	0	0
AC	Before contributing on code, I thought I need to review dl4j project. Translating will be good to study. __eou__	user	0	1	0	0
PF	Oh sure. __eou__	user	0	1	0	0
CQ	kepricon: is our engineer in korea __eou__	agent	0	1	0	0
FD	so he can review __eou__	agent	0	1	0	0
FD	we have 2 people there and little time :D so ANY help we can get is amazing __eou__	agent	0	1	0	0
CQ	Have you saw our korean channel? __eou__	agent	0	1	0	0
IG	 [<-LINK->]  __eou__	agent	0	1	0	0
IG	Feel free to ask questions there as well on wording and the like __eou__	agent	0	1	0	0
PF	Thanks for help! __eou__	user	0	1	0	0

OQ	I have a brain freeze about recurrent nets... All I'm trying to do is to evaluate a test set that is a timeseries data... and I can't figure out how to do it? do I have to feed the data one by one? __eou__	user	0	1	1	2
FD	because if I try to do it the "normal" way I get mismatch in label and predicted dimensions __eou__	user	0	1	0	0
CQ	using the Evaluation class? __eou__	agent	0	1	0	0
PA	you want evalTimeSeries for that __eou__	agent	0	1	0	0
JK	oh __eou__	user	0	1	0	0
IG	for the net, just use .output(INDArray features) __eou__	agent	0	1	0	0
JK	let me digest this for a moment __eou__	user	0	1	0	0
IG	 [<-LINK->]  __eou__	agent	0	1	0	0
FD	actually, just do that __eou__	agent	0	1	0	0
FD	MultiLayerNetwork.evaluate(DataSetIterator) if you can __eou__	agent	0	1	0	0
NF	AlexDBlack: something is still going wrong, let me clean up my code and post it as gist __eou__	user	0	1	0	0
IG	so if you remove the StatsListener you'll still get that output __eou__	agent	0	1	0	0
CQ	you're saying the scores actually change if you do that? __eou__	agent	0	1	0	0
IG	!gist __eou__	user	0	1	0	0
IG	To use gist: paste your code/exception/large output log into [<-LINK->] , click 'Create Secret Gist' and paste URL link here __eou__	agent	0	1	0	0
IG	what I'm trying to do is recurrent with one input and with 4 classes: [<-LINK->]  __eou__	user	0	1	0	0
IG	daredemo: ah, use an RnnOutputLayer, not an OutputLayer __eou__	agent	1	1	0	1
PF	AH! __eou__	user	0	1	0	0
PF	AlexDBlack: thanks a million __eou__	user	0	1	0	0
GG	sure, np __eou__	agent	0	1	0	0

AC	raver119: Let me train a new model in 0.7.0 and test it out once... if that fails too I will share the models and file an issue __eou__	user	0	0	0	0
AC	just post configurations you have, i'll do it faster :) __eou__	agent	0	0	0	0
IG	i know where to look there :) __eou__	agent	0	0	0	0
FD	raver119:  [<-LINK->] __eou__	user	0	0	0	0
CQ	how big is corpus? is it sentences or documents? __eou__	agent	0	0	0	0
FD	documents = set of sentences. i.e. text file. __eou__	agent	0	0	0	0
CC	documents __eou__	user	0	0	0	0
PF	amazing, thanks __eou__	agent	0	0	0	0
FQ	how big is it? how many documents, and what's average size of single document in bytes? __eou__	agent	0	0	0	0
IG	We have 3 different models  : 1 with 2 lakhs docs, 1 with 32k docs and last one with 476 docs... all have average 10-12 sentencesa __eou__	user	0	0	0	0
FQ	lakhs <- what's that word means? __eou__	agent	0	0	0	0
IG	0.2 mil __eou__	user	0	0	0	0
PF	aha, thanks. __eou__	agent	0	0	0	0

OQ	Hello, what happened to this page? __eou__	user	0	1	1	2
FD	 [<-LINK->]  __eou__	user	0	1	0	0
IG	Ettrai: Welcome! Here's a link to Deeplearning4j's Gitter Guidelines, our documentation and other DeepLearning resources online. Please explore these and enjoy! [<-LINK->]  __eou__	agent	0	1	0	0
CQ	Ettrai: there has been work to update the documents and that page was pulled. How did you get that link? __eou__	agent	0	1	0	0
IG	Ettrai: that page was out of date,  __eou__	agent	1	1	0	1
JK	echo. __eou__	agent	0	1	0	0
FD	Ettrai: also, what did you need to know about our architecture? __eou__	agent	0	1	0	0
IG	nyghtowl: @tomthetrainerI just used the search engine and a link provided in a paper. What I was trying to figure out is the parallelization strategies you are using __eou__	user	0	1	0	0
CQ	Ettrai: what is the paper you were looking at? __eou__	agent	0	1	0	0
IG	nyghtowl: it's from a double blind review so I cannot disclose it, sorry about that __eou__	user	0	1	0	0
CC	No problem - more just trying to understand where these links still exist __eou__	agent	0	1	0	0
PF	sure __eou__	user	0	1	0	0
IG	Regarding the parallelization strategy, we apply the batch training approach where we divide the gradient updates by the batch size __eou__	agent	1	1	0	1
GG	Thank you@nyghtowl.  __eou__	user	0	1	0	0
CQ	Ettrai: are you wondering about parallelism model for computations then? __eou__	agent	0	1	0	0
PF	raver119: I think that's what I am looking for. It would be nice to get the idea of how you carry on this computation, reduce, and so on __eou__	user	0	1	0	0

AE	internal maven is just convenience __eou__	user	0	1	1	2
OP	dl4j isn't that slow in a vm... using linux in a vm on windows it sometimes even outperforms the host __eou__	user	0	1	0	0
JK	huh __eou__	agent	0	1	0	0
CQ	linux > windows I assume? __eou__	agent	0	1	0	0
PF	right __eou__	user	0	1	0	0
IG	That sometimes happens. __eou__	agent	0	1	0	0
CC	my point is that putting it in a vm isn't usually a huge performance cost __eou__	user	0	1	0	0
IG	The opposite is also true sometimes.  Chrome is faster inside a VM running windows on a Linux host. __eou__	agent	1	1	0	1
FD	Especially CPU bound stuff. __eou__	agent	1	1	0	1
FD	Once you start doing IO though. __eou__	agent	1	1	0	1
IG	I find that on SSDs it's pretty good __eou__	user	0	1	0	0

OQ	I learn some examples from named directories, unfortunately I only can see the indexes of the labels but not its names where loaded from, are these persisted in the model somewhere or do I have to care of it in the learning stage when loaded via FileSplit? __eou__	user	0	1	1	2
IG	thhart: that's where the record meta data comes in __eou__	agent	1	1	0	1
FQ	agibsonccc: But metadata I know for the datasets during learning, is there also metadata to store within a model for the labels? __eou__	user	0	1	0	0
IG	thhart: you'd have to track that yourself __eou__	agent	1	1	0	1
FD	we are working on a more integrated pipeline api that will allow this to be a bit less opaque __eou__	agent	1	1	0	1
FD	if you have any ideas for features feel free to open an issue __eou__	agent	1	1	0	1

OQ	@/allwe're planning on building Keras bindings for DL4J. Is anyone in this thread interested in and available for contributing (part-time, remote) to that? if so, pls DM me... __eou__	user	0	0	0	0

OQ	raver120: is there any chinese edition of this book? __eou__	user	0	1	1	2
CC	raver120 is a bot :D __eou__	agent	0	1	0	0
IG	we are translating it to mandarin with oreilly __eou__	agent	1	1	0	1
FD	but it won't be out for a while __eou__	agent	1	1	0	1
FD	If you want more information add me on wechat __eou__	agent	1	1	0	1
FD	agibsonccc __eou__	agent	1	1	0	1
UF	ok __eou__	user	0	1	0	0
IG	I can point you in the right direction __eou__	agent	0	1	0	0
FD	we have a wechat presence __eou__	agent	0	1	0	0
FD	we also do a lot of business in china __eou__	agent	0	1	0	0
PF	thanks a lot __eou__	user	0	1	0	0
IG	i begin to learn dl4j for a little days, and  have lots of questions to ask.   __eou__	user	0	1	0	0
FQ	wechat?the Chinese IM tool from Tecent?@agibsonccc __eou__	agent	0	1	0	0
IG	Yes I use wechat __eou__	agent	0	1	0	0
JK	actively __eou__	agent	0	1	0	0
FD	I was just in china for all of november :D __eou__	agent	0	1	0	0
FD	I live in asia __eou__	agent	0	1	0	0
FD	I spoke here just recently: [<-LINK->]  __eou__	agent	0	1	0	0

GG	hellow! __eou__	user	0	0	0	0
IG	1151738113: Welcome! Here's a link to Deeplearning4j's Gitter Guidelines, our documentation and other DeepLearning resources online. Please explore these and enjoy! [<-LINK->] __eou__	agent	0	0	0	0

GG	Hi Adam __eou__	user	0	0	0	0
OQ	how is it going? __eou__	user	0	0	0	0
IG	sunilkumartc: late in san francisco :D I'm passing out in a few __eou__	agent	0	0	0	0
IG	I know.Its day in Bangalore,India __eou__	user	0	0	0	0
PF	yup I usually live in japan __eou__	agent	0	0	0	0
FD	I'm used to time zones __eou__	agent	0	0	0	0
FD	1 of those things :D __eou__	agent	0	0	0	0
FD	Anyways - have a good "day" feel free to ask questions, my colleagues are awake __eou__	agent	0	0	0	0
PF	Cool.will do. __eou__	user	0	0	0	0

OP	raver119: I just tried to change "<artifactId>nd4j-native</artifactId>" to "<artifactId>nd4j-native-platform</artifactId>", but it doesn't work. It's also that error. can\'t find jniopenblas.dll __eou__	user	0	1	1	2
CQ	Give us a !gist of the full stack trace then __eou__	agent	0	1	0	0
IG	To use gist: paste your code/exception/large output log into [<-LINK->] , click 'Create Secret Gist' and paste URL link here __eou__	agent	0	1	0	0
FD	and add output of java —version please __eou__	agent	0	1	0	0
IG	java version "1.8.0_111"Java(TM) SE Runtime Environment (build 1.8.0_111-b14)Java HotSpot(TM) 64-Bit Server VM (build 25.111-b14, mixed mode) __eou__	user	0	1	0	0
CQ	yeah we'll need your full error __eou__	agent	0	1	0	0
IG	 [<-LINK->]  __eou__	user	0	1	0	0
PF	ahh __eou__	agent	0	1	0	0
IG	add javacv as a dependency __eou__	agent	0	1	0	0
FD	 [<-CODE->]  __eou__	agent	0	1	0	0
AC	I 'll try it. __eou__	user	0	1	0	0
NF	aha.. The fact is that it also doesn't work...the same error. __eou__	user	0	1	0	0
IG	your error is definitely opencv related __eou__	agent	0	1	0	0
JK	look at it __eou__	agent	0	1	0	0
JK	oh wait __eou__	agent	0	1	0	0
CC	I was looking at opencv :D __eou__	agent	0	1	0	0
FD	I read that as opencv not openblas __eou__	agent	0	1	0	0
FD	that's a bit weird __eou__	agent	0	1	0	0
NF	my bad __eou__	agent	0	1	0	0
CQ	if openblas isn't statically linked it might need to be installed? hm __eou__	agent	0	1	0	0
JK	... __eou__	user	0	1	0	0
NF	I'm not sure what the deal is on windows __eou__	agent	0	1	0	0
NF	Yeah my bad :D let's move on here __eou__	agent	0	1	0	0
IG	sorry we've ran in to that before __eou__	agent	1	1	0	1
FD	pretty common cause __eou__	agent	1	1	0	1
FD	usually people  need to install opencv in order to use it, it looks like something similar here __eou__	agent	1	1	0	1
PA	markWZX: Installing openblas here: [<-LINK->] and putting this folder on your path should work __eou__	agent	1	1	0	1
UF	OK. __eou__	user	0	1	0	0
IG	Also if you don\'t know what I\'m talking about with "linking" you should at least vaguely know what that is __eou__	agent	1	1	0	1
FD	Look, I can tell you're kinda impatient with this, but native stuff is more or less always like this on windows :D __eou__	agent	1	1	0	1

